{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 hw2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "Additional note: data you download for use in this assignment **should not be pushed to your repository**. You will lose marks for pushing datasets to your repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting familiar with the *fit* and *predict* paradigm. \n",
    "\n",
    "The idea of a machine learning algorithm is to *fit* the best model on the given training data (which is in the form of feature vectors and their targets) and then using this model to *predict* targets for new examples (represented with feature vectors.) Below we show an example of using these paradigms with a toy dataset. The goal is to predict fruit type given fruit's diameter and whether or not it is sweet. (Note: this is a very silly and contrived example, since if you've already taken a bite to see if it's sweet then you probably already know what type of fruit you are dealing with!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sweet</th>\n",
       "      <th>diameter</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sweet  diameter target\n",
       "0         0         3  Apple\n",
       "1         0         3  Apple\n",
       "2         1         1  Grape\n",
       "3         1         1  Grape\n",
       "4         0         3  Lemon\n",
       "5         1         1  Grape\n",
       "6         0         4  Apple"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_data = {\n",
    "    # Features\n",
    "    'is_sweet': [0, 0, 1, 1, 0, 1, 0],\n",
    "    'diameter': [3, 3, 1, 1, 3, 1, 4],\n",
    "    # Target\n",
    "    'target': ['Apple', 'Apple', 'Grape', 'Grape', 'Lemon', 'Grape', 'Apple']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(toy_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a decision tree model using sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the tree module of sklearn\n",
    "from sklearn import tree \n",
    "\n",
    "# instantiate a class of the DecisionTreeClassifier\n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# prepare data for model fitting\n",
    "X = df[['is_sweet','diameter']]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the data. The semicolon at the end is used to suppress displaying the output of model.fit\n",
    "model.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Apple', 'Apple', 'Grape', 'Grape', 'Apple', 'Grape', 'Apple'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use the .predict method of our model class to make predictions\n",
    "predictions = model.predict(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the true fruit identities, we can compare the predictions of our tree model to the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sweet</th>\n",
       "      <th>diameter</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Grape</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Grape</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lemon</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Grape</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sweet  diameter target prediction\n",
       "0         0         3  Apple      Apple\n",
       "1         0         3  Apple      Apple\n",
       "2         1         1  Grape      Grape\n",
       "3         1         1  Grape      Grape\n",
       "4         0         3  Lemon      Apple\n",
       "5         1         1  Grape      Grape\n",
       "6         0         4  Apple      Apple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prediction'] = predictions\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model made an _error_ on example with index 4, which is a **Lemon** but was predicted to be an **Apple**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the trained decision tree using the `graphviz` package\n",
    "\n",
    "We will be using the [graphviz](https://graphviz.readthedocs.io/en/stable/manual.html) package to visualize the trained decision tree model. It may be somewhat annoying to install graphviz on some systems. Therefore, you are not required to install graphviz and run the code below; instead, you can simply observe the output shown below. Having said that, you are encouraged to install graphviz and actually run the code! It was fairly painless to install on my Mac. \n",
    "\n",
    "Mac or Linux users: You will have to install the package using\n",
    "\n",
    "       conda install python-graphviz\n",
    "\n",
    "and/or (possibly both) \n",
    "\n",
    "       pip install python-graphviz\n",
    "\n",
    "Windows users: You might have to install both the [software](https://graphviz.gitlab.io/_pages/Download/Download_windows.html) and the package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"317pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 317.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-310 313,-310 313,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M166,-306C166,-306 77,-306 77,-306 71,-306 65,-300 65,-294 65,-294 65,-235 65,-235 65,-229 71,-223 77,-223 77,-223 166,-223 166,-223 172,-223 178,-229 178,-235 178,-235 178,-294 178,-294 178,-300 172,-306 166,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">diameter ≤ 2.0</text>\n",
       "<text text-anchor=\"start\" x=\"85\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.612</text>\n",
       "<text text-anchor=\"start\" x=\"83.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7</text>\n",
       "<text text-anchor=\"start\" x=\"73\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 3, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"79.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Apple</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#39e581\" stroke=\"#000000\" d=\"M101,-179.5C101,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 101,-111.5 101,-111.5 107,-111.5 113,-117.5 113,-123.5 113,-123.5 113,-167.5 113,-167.5 113,-173.5 107,-179.5 101,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"27.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"18.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 3, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"13\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Grape</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M98.7662,-222.8796C92.7599,-211.8835 86.263,-199.9893 80.2067,-188.9015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.1088,-186.9133 75.2435,-179.8149 76.9655,-190.2689 83.1088,-186.9133\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.2034\" y=\"-200.1032\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#eeab7b\" stroke=\"#000000\" d=\"M232,-187C232,-187 143,-187 143,-187 137,-187 131,-181 131,-175 131,-175 131,-116 131,-116 131,-110 137,-104 143,-104 143,-104 232,-104 232,-104 238,-104 244,-110 244,-116 244,-116 244,-175 244,-175 244,-181 238,-187 232,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"142.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">diameter ≤ 3.5</text>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n",
       "<text text-anchor=\"start\" x=\"149.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"145.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Apple</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M144.5836,-222.8796C149.3789,-214.2335 154.4822,-205.0322 159.4338,-196.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.5284,-197.7407 164.3179,-187.2981 156.4069,-194.3455 162.5284,-197.7407\"/>\n",
       "<text text-anchor=\"middle\" x=\"171.2031\" y=\"-207.6313\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#f2c09c\" stroke=\"#000000\" d=\"M166,-68C166,-68 77,-68 77,-68 71,-68 65,-62 65,-56 65,-56 65,-12 65,-12 65,-6 71,0 77,0 77,0 166,0 166,0 172,0 178,-6 178,-12 178,-12 178,-56 178,-56 178,-62 172,-68 166,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"85\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"83.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"73\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"79.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Apple</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M162.924,-103.9815C157.7014,-95.1585 152.1771,-85.8258 146.9237,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"149.8874,-75.0863 141.7816,-68.2637 143.8636,-78.652 149.8874,-75.0863\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M297,-68C297,-68 208,-68 208,-68 202,-68 196,-62 196,-56 196,-56 196,-12 196,-12 196,-6 202,0 208,0 208,0 297,0 297,0 303,0 309,-6 309,-12 309,-12 309,-56 309,-56 309,-62 303,-68 297,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"223.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"214.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"204\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 0, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"210.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Apple</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M211.7036,-103.9815C216.8471,-95.1585 222.2877,-85.8258 227.4616,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.513,-78.6656 232.5257,-68.2637 224.4656,-75.1402 230.513,-78.6656\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1bdf2518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to plot our model (hint: you'll use this function later too)\n",
    "def save_and_show_decision_tree(model, \n",
    "                                class_names,\n",
    "                                feature_names,\n",
    "                                save_file_prefix = 'test'):\n",
    "    \"\"\"\n",
    "    Saves the decision tree model as a pdf and shows how the data is split and \n",
    "    classified\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: sklearn.tree.DecisionTreeClassifier\n",
    "        The sklearn decision tree\n",
    "    class_names : list\n",
    "        The names of all the possible classifications\n",
    "    feature_names : list\n",
    "        The names of all the features\n",
    "    save_file_prefix: str\n",
    "        The name you wish to save the file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    graphviz.files.Source\n",
    "        The decision tree graph\n",
    "    \"\"\"\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                             feature_names=feature_names,  \n",
    "                             class_names=class_names,  \n",
    "                             filled=True, rounded=True,  \n",
    "                             special_characters=True)  \n",
    "\n",
    "    graph = graphviz.Source(dot_data) \n",
    "#     graph.render(save_file_prefix) \n",
    "    return graph\n",
    "\n",
    "graph = save_and_show_decision_tree(model,\n",
    "                                    class_names = ['Apple', 'Grape', 'Lemon'],\n",
    "                                    feature_names = ['is_sweet','diameter'])\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2cd388d38fd80775",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1: Interpreting the decision tree <a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-094df3962a003faf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 1(a)\n",
    "rubric={points:3}\n",
    "\n",
    "For each split in thie decision tree, briefly describe the splitting criterion and what data goes on each side of the split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9c70ede2aef9373a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b54ba524bfd3cb8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 1(b)\n",
    "rubric={points:2}\n",
    "\n",
    "Discuss the predictions on the training data. Why is the example `is_sweet` = 0 and `diameter` = 3 classified as *Apple* even though in the training data its target is *Lemon*? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-40326ff1d0667b49",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exercise 2: Exploratory Data Analysis <a name=\"2\"></a>\n",
    " \n",
    " \n",
    "For the rest of the assignment you'll be using Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset.\n",
    "The dataset contains a number of features of songs from 2017 and a binary variable `target` that represents whether the user liked the song or not. See the documentation of all the features [here](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/). The question we will focus on is what kinds of songs the user likes.\n",
    "\n",
    "This dataset is publicly available on Kaggle, and you will have to download it yourself. Follow the steps below to get the data CSV. \n",
    "\n",
    "1. If you do not have an account with [Kaggle](https://www.kaggle.com/), you will first need to create one (it's free).\n",
    "2. Login to your account and [download](https://www.kaggle.com/geomack/spotifyclassification/download) the dataset.\n",
    "3. Unzip the data file, rename it to `spotify.csv`, and move it to the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4d478b6cdc9bf88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 2(a) \n",
    "rubric={points:1}\n",
    "\n",
    "Read in the data CSV and store it as a pandas dataframe named `spotify_df`. The first column of the .csv file should be set as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4f3f14b59fd7e6b8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(b)\n",
    "rubric={points:2}\n",
    "\n",
    "Show some summary statistics of each feature using the `describe` method. Which feature has the smallest range (max-min)? Note that `describe` returns another DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b33320bcf667584a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 2(c) \n",
    "rubric={points:4}\n",
    "\n",
    "Produce histograms for the following features (in order) that show the distribution of the feature values, **separated for positive and negative target values**  (it should look something vaguely like [this](https://i.stack.imgur.com/acUlv.png)). As a reminder, the target class represents whether the user liked the song (1) or not (0).\n",
    "\n",
    "- danceability\n",
    "- tempo\n",
    "- instrumentalness\n",
    "- valence\n",
    "\n",
    "Note: To adhere to the [DRY (Don't Repeat Yourself)](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) principle, you should use a `for` loop for your plotting, rather than repeating the plotting code 4 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(d)\n",
    "rubric={points:3}\n",
    "\n",
    "Let's say you had to make a decision tree, _by hand_, to predict the target class. Just from looking at the plots above, describe a reasonable split and what class you would predict in the two cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(e)\n",
    "rubric={points:2}\n",
    "\n",
    "Let's say that, for a particular feature, the histograms of that feature are completely identical for the two target classes. Does that mean the feature is not useful for predicting the target class?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86f9e0c649669daf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2(f) \n",
    "rubric={points:2}\n",
    "\n",
    "- Note that the dataset includes two free text features labeled `song_title` and `artist`. Do you think these features could be useful in predicting whether the user liked the song or not? \n",
    "- Would there be any difficulty in using them in your model?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dce517defdc16360",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1440876fbc49ead5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3: Using sklearn to build a decision tree classifier <a name=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-706403e72adade4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 3(a) Fitting a  `DecisionTreeClassifier`  \n",
    "rubric={points:3}\n",
    "\n",
    "- Create `X` and `y` from the Spotify dataset. Skip the `song_title` and `artist` features for now. \n",
    "- Split the spotify dataset into a 80% train and 20% test using `sklearn.model_selection.train_test_split`.\n",
    "- Fit a `DecisionTreeClassifier` on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-859d4a70667da85d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-43ac6f91bc3bd9da",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 3(b)\n",
    "rubric={points:2}\n",
    "\n",
    "Use the `predict` method to predict the class of the first example in your `X_train` and `X_test`. Are these predictions accurate? That is, do they match with the corresponding classes in `y_train` and `y_test`?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(c) \n",
    "rubric={points:2}\n",
    "\n",
    "Use the `score` method to compute the training accuracy and testing accuracy of your model. Display the results to 3 decimal places. ([Here](https://realpython.com/python-f-strings/) is an article on how to format the number of decimal places. Use `.3f` to get a float to 3 decimal places.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(d)\n",
    "rubric={points:1}\n",
    "\n",
    "Do you see a difference in the train and test accuracies? Discuss the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a89757274fc5586f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4150979c1845a18c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4: Hyperparameters <a name=\"4\"></a>\n",
    "rubric={points:10}\n",
    "\n",
    "In this exercise, you'll experiment with different hyperparameters of the decision tree classifier. See the [`DecisionTreeClassifier` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more details.\n",
    "\n",
    "1. Split the spotify dataset into a 80% train and 20% test subset using `sklearn.model_selection.train_test_split()`.\n",
    "2. Explore the `max_depth` hyperparameter. Train decision tree models with different values of `max_depth` (at least 10 different values in the range 1 to 25) on the training data.\n",
    "3. For each `max_depth`, find the accuracy of the model on the train subset and the test subset.\n",
    "4. Make a plot with the depth of the decision tree on the *x*-axis and the accuracy on the train and test sets on the *y*-axis.\n",
    "5. Discuss how changing the `max_depth` hyperparameter affects the training and test accuracy. From these results, what depth would you pick as the optimal depth? Do you think that the depth you chose would generalize to other \"spotify\" datasets (i.e., spotify datasets for other users)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-333a326eff884930",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Conceptual questions\n",
    "rubric={points:3}\n",
    "\n",
    "Consider the dataset below, which has $6$ examples and $2$ features:\n",
    "\n",
    "$$ X = \\begin{bmatrix}5 & 2\\\\4 & 3\\\\  2 & 2\\\\ 10 & 10\\\\ 9 & -1\\\\ 9& 9\\end{bmatrix}, \\quad y = \\begin{bmatrix}-1\\\\-1\\\\+1\\\\+1\\\\+1\\\\+1\\end{bmatrix}.$$\n",
    "\n",
    "1. Say we fit a decision stump and the first split is on the first feature (left column) being less than 5.5. What would we predict in the \"true\" and \"false\" cases here?\n",
    "2. What training accuracy would the above stump get on this data set?\n",
    "3. Can we obtain 100% accuracy with a single decision stump?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
