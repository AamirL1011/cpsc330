{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 hw3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from plot_classifier import plot_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={points:5}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "**NEW REQUIREMENT**: if you are working with a partner, you must write a few sentences explaining the contribution of each team member. You should refer to yourselves by your CSIDs (because seeing names can cause bias during grading). Here is an example:\n",
    "\n",
    "> a1b2c did Exercise 1, checked over Exercise 2, and pair-programmed for Exercise 3. z9y8x checked over Exercise 1, did Exercise 2, and pair-programmed for Exercise 3. \n",
    "\n",
    "Our ideal scenario is that you worked together on all the exercises, but you are not required to do so, and for now we are only collecting this information because we are curious. If you are working alone, you can ignore this section.\n",
    "\n",
    "_YOUR TEAMWORK CONTRIBUTION STATEMENT GOES HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e3cc53df86a7e14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Exercise 1: Data and preprocessing <a name=\"1\"></a>\n",
    "We will be focusing on the classification task of predicting the presence or absence of heart disease (the response) based on a set of 13 different biophysical measures (the features). The classification of heart disease in patients is obviously of great importance for cardiovascular disease diagnosis and prevention. Machine learning offers novel and potentially effective methods of forming predictive models from heart disease data. The dataset you will be working with has been made available by the UCI Machine Learning Repository [here](https://archive.ics.uci.edu/ml/datasets/Heart+Disease). A slightly modified version of this dataset has been made available in your repo as `heart_disease.csv`. You will see that it contains 303 observations (patients) and 14 columns (13 features and 1 response).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df = pd.read_csv('heart_disease.csv', index_col=0)\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Ordering the steps\n",
    "rubric={points:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to wrangle this dataset into a format suitable for use with the `scikit-learn` library. This includes:\n",
    "\n",
    "1. Loading the dataset;\n",
    "2. Feature preprocessing (one-hot encoding and scaling); and,\n",
    "3. Splitting data into train/validation/test sets.\n",
    "\n",
    "To help you understand this wrangling process, the code required to perform the pre-processing tasks above is provided. The code has been arranged into different blocks performing the tasks above but these blocks are in the wrong order. Rearrange the code to correctly wrangle the data and add a short comment to each block to describe what the code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cadffc5ad33d4efb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR COMMENT HERE\n",
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train),\n",
    "                       index=X_train.index,\n",
    "                       columns=(numeric_features +\n",
    "                                list(preprocessor.named_transformers_['ohe']\n",
    "                                     .get_feature_names(categorical_features))))\n",
    "\n",
    "X_valid = pd.DataFrame(preprocessor.transform(X_valid),\n",
    "                      index=X_valid.index,\n",
    "                      columns=X_train.columns)\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "numeric_features = ['age', 'resting_blood_pressure', 'cholesterol',\n",
    "                    'max_heart_rate_achieved', 'st_depression', 'num_major_vessels']\n",
    "categorical_features = ['sex', 'chest_pain_type', 'fasting_blood_sugar', 'rest_ecg',\n",
    "                        'exercise_induced_angina', 'st_slope', 'thalassemia']\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train,\n",
    "                                                      y_train,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=50)\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', StandardScaler(), numeric_features),\n",
    "        ('ohe', OneHotEncoder(drop=\"first\"), categorical_features)])\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "heart_df = pd.read_csv('heart_disease.csv', index_col=0)\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(heart_df.drop(columns='target'),\n",
    "                                                    heart_df['target'],\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Exploring the one-hot encoding\n",
    "rubric={points:3}\n",
    "\n",
    "The original dataset had a feature called `st_slope`. \n",
    "\n",
    "1. What were the possible values of this feature? \n",
    "2. What new binary feature(s) were created to replace this feature? \n",
    "3. For each possible value of the original feature, how is this value represented in the transformed data? For example, the original feature `rest_ecg` had two values, \"normal\" and \"abnormal\". In the transformed data, the new feature is called `rest_ecg_normal`, where \"normal\" is represented as 1.0 and \"abnormal\" is represented as 0.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise 2: Logistic regression <a name=\"2\"></a>\n",
    "In this exercise you will work with a type of linear model known as *logistic regression*. Recall that logistic regression, despite the name, is used for classification tasks. Typically it is used to model the relationship between one dependent binary variable (the target) and one or more numerical or categorical independent variables (features). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba1f8ea22638cf75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Train a logistic regression model\n",
    "rubric={points:1}\n",
    "\n",
    "Fit a [Logistic Regression classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) called `lgr` on the train split of the heart disease data. You can use all default hyperparameters. If you get a `FutureWarning`, you can ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac288c544f903a4b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88e74a14ba41ec10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Test the model\n",
    "rubric={points:2}\n",
    "\n",
    "1. Test the `lgr` model on the training split of the heart disease data.\n",
    "2. Test the `lgr` model on the validation split of the heart disease data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9a3243af6dc8544",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-672df1d9838d30c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 Interpret the test outputs\n",
    "rubric={points:1}\n",
    "\n",
    "Based on your results from **Q2.2** would you say your logisitic regression model is overfit? Why/why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-18a759294ddb5c8f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f910e9d1d6d09182",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.4 Predicting probabilities\n",
    "rubric={points:6}\n",
    "\n",
    "A logistic regression model outputs a probability between 0 and 1, where (typically) probabilities less than 0.5 are assigned to class 0 and probabilites greater than 0.5 are assigned to class 1. The predictions of the logistic regression model can be revealed through the `.predict_proba()` method.\n",
    "\n",
    "1. What is the predicted probability that the first observation in the validation set (observation 11) has heart disease (target = 1)?\n",
    "1. What is the largest predicted probability across the entire validation set?\n",
    "1. What is the ID of the patient with this highest predicted probability of heart disease in the validation set (give the actual ID number, not the index location)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-74975ac4dc07df4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.5 Most important features for predicting heart disease\n",
    "rubric={points:5}\n",
    "\n",
    "We can investigate the coefficient values of our logistic regression model to help understand the importance of the different features. Information of the coefficients is exposed by the `coef_` attribute of your `lgr` model (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for more help). What are the 3 most important features in the model according to the absolute value of the coefficients?\n",
    "\n",
    "What is the difference between a positive and negative coefficient in your `lgr` model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0b6ca9c2acce547f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise 3: Support vector machine (SVM) <a name=\"3\"></a>\n",
    "\n",
    "In this exercise, you will use train a SVM on the heart disease dataset and compare results to the logistic regression model from **Exercise 2**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b705b7463d3c6181",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.1 Kernels in SVM classification\n",
    "rubric={points:5}\n",
    "\n",
    "The sklearn [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) allows several different values for its `kernel` argument, including `'linear'`, `'poly'`, and `'rbf'`. For each of these kernels, train a model and report the training and validation accuracy. Make sure you use a `for` loop instead of repeating your code 3 times. To avoid issues with the newer sklearn, set `gamma='auto'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ec6fa3df244b135",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Interpreting results\n",
    "rubric={points:3}\n",
    "\n",
    "How do the train and validation accuracies compare to the logistic regression classifier in **Exercise 2**? Are any of the models overfit? Based on your results, why do you think the `'rbf'` kernel is the default in `scikit-learn`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5aba949b83841f25",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cbc32fb4b43125c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3 Visualizing results\n",
    "rubric={points:3}\n",
    "\n",
    "To understand the effect of the different `SVC` kernels it may be helpful to visualize them. We can easily visualize decision boundaries in 2-dimensions (i.e., 2 input features). The code below visualizes the 3 different kernels you tried above using a subset of the training data with only 2 features and only 30% of the examples. Run the code and *briefly* comment on/describe the behaviour of the three different kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract some sample 2-d data, set the random_state for repeatability and matching X/y samples\n",
    "sample = (X_train[['age', 'cholesterol']].join(y_train)\n",
    "                                         .sample(frac=0.3, random_state=123)\n",
    "                                         .dropna())\n",
    "sample_X, sample_y = sample.drop(columns=\"target\"), sample[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "for i, kernel in enumerate(kernels):\n",
    "    SVC_model = SVC(kernel=kernel, gamma=\"auto\")\n",
    "    SVC_model.fit(sample_X, sample_y)\n",
    "    plt.subplot(1,3,i+1)\n",
    "    ax = plt.gca()\n",
    "    plot_classifier(sample_X, sample_y, SVC_model, ax=ax, ticks=True)\n",
    "    ax.set_title(kernel);\n",
    "    ax.set_xlabel('age (scaled)')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('cholesterol (scaled)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-48027c063d99bc4b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc56fdd1f387082c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.4 The RBF kernel hyperparameters\n",
    "rubric={points:5}\n",
    "\n",
    "`gamma` and `C` are hyperparameters of the `SVC` model, specifically for the RBF kernel. Both of them affect the complexity of the model. In this exercise we'll focus `gamma` specifically.\n",
    "\n",
    "Your task is to explore different values of `gamma`: \n",
    "\n",
    "1. Set `gamma` to $0.001, 0.01, 0.1, 1$ and $10$, once again using a `for` loop instead of repeating your code. Inside the loop, fit the model on the original training data and report the training and validation accuracy. \n",
    "2. Furthermore, for each `gamma`, fit another `SVC` model on only the smaller dataset from the previous exercise, and produce a decision boundary plot similar to the ones above. \n",
    "3. Then, discuss your results. How does `gamma` influence your results? Can you relate this to the fundamental trade-off of ML models? Do you get more complicated surfaces from larger `gamma`, or smaller?\n",
    "\n",
    "Note: your accuracy printouts won't correspond exactly to the plots, because the accuracy scores come from the full dataset and the plots are only made using the subsetted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise 4: Open-Ended <a name=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e9e6fdea209d872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4.1 Try to maximize valdiation accuracy\n",
    "rubric={points:6}\n",
    "\n",
    "Using any of `LogisticRegression`, `SVC`, `DecisionTreeClassifier` and `RandomForestClassifier`, try to get the best validation accuracy that you can on this same data set. You'll want to fiddle with the hyperparameters. When you are done, briefly describe what you tried and what worked best.\n",
    "\n",
    "Note: this question is quite open-ended. I recommend not spending more than 20 minutes on it, and just submitting what you have after 20 min. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test set\n",
    "rubric={points:3}\n",
    "\n",
    "Evaluate your final model on the test set. How does your test accuracy compare to your validation accuracy? If they are different: do you think this is because you \"overfitted on the validation set\", or simply random luck? Discuss your answer in the context of the size of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Cross-validation\n",
    "rubric={points:1}\n",
    "\n",
    "Would this problem be a good candidate for using cross-validation, instead of a train/validation split? Briefly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
