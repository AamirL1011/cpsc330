{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 2: Terminology, Baselines, Decision Trees\n",
    "\n",
    "UBC 2021-22\n",
    "\n",
    "Instructor: Varada Kolhatkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"code/.\")\n",
    "import graphviz\n",
    "import IPython\n",
    "import mglearn\n",
    "from IPython.display import HTML, display\n",
    "from plotting_functions import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "from utils import *\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements \n",
    "\n",
    "- hw1 due tonight at 11:59pm\n",
    "- hw2 will be released tomorrow, due Monday 11:59pm\n",
    "  - See [here](https://github.com/UBC-CS/cpsc330/blob/master/docs/homework_instructions.md#groups) for instructions on working with a partner.\n",
    "  - You are free to work alone or with a partner.\n",
    "- On the usual schedule, hw will be due Mondays and released Tuesdays\n",
    "- My evening office hour moved from Wed to Thu \n",
    "  - Note I have 30 min morning OH and 30 min evening OH.\n",
    "- Update on the plan for the final exam:\n",
    "  - We will **not** have a regular 2.5 hour exam in the regular way.\n",
    "  - There will be a take-home, with a mix of coding and conceptual questions.\n",
    "  - The time window will be 24-48 hours (exact time window TBD).\n",
    "  - Open book.\n",
    "- Update on the plan for the midterm:\n",
    "  - We'll do it on Canvas during class time on Oct 22.\n",
    "  - This will be the one time you'll need to operate in the middle of the night if you're in a far time zone (sorry).\n",
    "  - Probably open book.\n",
    "- Please monitor Piazza (especially pinned posts and instructor posts) for announcements.\n",
    "- Sorry for the setup difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Learning outcomes \n",
    "From this lecture, you will be able to \n",
    "\n",
    "- identify whether a given problem could be solved using supervised machine learning or not; \n",
    "- differentiate between supervised and unsupervised machine learning;\n",
    "- explain machine learning terminology such as features, targets, predictions, training, and error;\n",
    "- differentiate between classification and regression problems;\n",
    "- use `DummyClassifier` and `DummyRegressor` as baselines for machine learning problems;\n",
    "- explain the `fit` and `predict` paradigm and use `score` method of ML models; \n",
    "- broadly describe how decision tree prediction works;\n",
    "- use `DecisionTreeClassifier` and `DecisionTreeRegressor` to build decision trees using `scikit-learn`; \n",
    "- visualize decision trees; \n",
    "- explain the difference between parameters and hyperparameters; \n",
    "- explain the concept of decision boundaries;\n",
    "- explain the relation between model complexity and decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big picture and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy datasets \n",
    "\n",
    "We will be working with three toy datasets \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🤔 Eva's questions\n",
    "\n",
    "![](img/eva-think.png)\n",
    "\n",
    "At this point Eva is wondering about the following questions. \n",
    "\n",
    "- What might be the difference between spam filtering vs. Google News?   \n",
    "- What might be the difference between predicting spam vs. predicting housing prices? \n",
    "\n",
    "Think about these questions on your own or discuss them with your friend/neighbour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Terminology\n",
    "\n",
    "You will see a lot of variable terminology in machine learning and statistics. Let's familiarize ourselves with some of the basic terminology used in ML. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I'll be using the following grade prediction toy dataset to demonstrate the terminology. Imagine that you are taking a course with four home work assignments and two quizzes. You and your friends are quite nervous about your quiz2 grades and you want to know how will you do based on your previous performance and some other attributes. So you decide to collect some data from your friends from last year and train a supervised machine learning model for quiz2 grade prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_experience</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>lab1</th>\n",
       "      <th>lab2</th>\n",
       "      <th>lab3</th>\n",
       "      <th>lab4</th>\n",
       "      <th>quiz1</th>\n",
       "      <th>quiz2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>not A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>not A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ml_experience  class_attendance  lab1  lab2  lab3  lab4  quiz1   quiz2\n",
       "0              1                 1    92    93    84    91     92      A+\n",
       "1              1                 0    94    90    80    83     91  not A+\n",
       "2              0                 0    78    85    83    80     80  not A+\n",
       "3              0                 1    91    94    92    91     89      A+\n",
       "4              0                 1    77    83    90    92     85      A+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "print(classification_df.shape)\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Supervised machine learning\n",
    "\n",
    "<img src=\"img/sup-learning.png\" height=\"800\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tabular data\n",
    "In supervised machine learning, the input data is typically organized in a **tabular** format, where rows are **examples** and columns are **features**. One of the columns is typically the **target**. \n",
    "\n",
    "<img src=\"img/sup-ml-terminology.png\" height=\"1000\" width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Features** \n",
    ": Features are relevant characteristics of the problem, usually suggested by experts. Features are typically denoted by $X$ and the number of features is usually denoted by $d$.  \n",
    "\n",
    "**Target**\n",
    ": Target is the feature we want to predict (typically denoted by $y$). \n",
    "\n",
    "**Example** \n",
    ": A row of feature values. When people refer to an example, it may or may not include the target corresponding to the feature values, depending upon the context. The number of examples is usually denoted by $n$. \n",
    "\n",
    "**Training**\n",
    ": The process of learning the mapping between the features ($X$) and the target ($y$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Tabular data for grade prediction\n",
    "\n",
    "The tabular data usually contains both: the features (`X`) and the target (`y`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_experience</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>lab1</th>\n",
       "      <th>lab2</th>\n",
       "      <th>lab3</th>\n",
       "      <th>lab4</th>\n",
       "      <th>quiz1</th>\n",
       "      <th>quiz2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>not A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>not A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ml_experience  class_attendance  lab1  lab2  lab3  lab4  quiz1   quiz2\n",
       "0              1                 1    92    93    84    91     92      A+\n",
       "1              1                 0    94    90    80    83     91  not A+\n",
       "2              0                 0    78    85    83    80     80  not A+\n",
       "3              0                 1    91    94    92    91     89      A+\n",
       "4              0                 1    77    83    90    92     85      A+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So the first step in training a supervised machine learning model is separating `X` and `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_experience</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>lab1</th>\n",
       "      <th>lab2</th>\n",
       "      <th>lab3</th>\n",
       "      <th>lab4</th>\n",
       "      <th>quiz1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ml_experience  class_attendance  lab1  lab2  lab3  lab4  quiz1\n",
       "0              1                 1    92    93    84    91     92\n",
       "1              1                 0    94    90    80    83     91\n",
       "2              0                 0    78    85    83    80     80\n",
       "3              0                 1    91    94    92    91     89\n",
       "4              0                 1    77    83    90    92     85"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        A+\n",
       "1    not A+\n",
       "2    not A+\n",
       "3        A+\n",
       "4        A+\n",
       "Name: quiz2, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Tabular data for the housing price prediction\n",
    "\n",
    "Here is an example of tabular data for housing price prediction. You can download the data from [here](https://www.kaggle.com/harlfoxem/housesalesprediction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.read_csv(\"data/kc_house_data.csv\")\n",
    "housing_df.drop([\"id\", \"date\"], axis=1, inplace=True)\n",
    "HTML(housing_df.head().to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
       "0         3       1.00         1180      5650     1.0           0     0   \n",
       "1         3       2.25         2570      7242     2.0           0     0   \n",
       "2         2       1.00          770     10000     1.0           0     0   \n",
       "3         4       3.00         1960      5000     1.0           0     0   \n",
       "4         3       2.00         1680      8080     1.0           0     0   \n",
       "\n",
       "   condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0          3      7      1180.0              0      1955             0   \n",
       "1          3      7      2170.0            400      1951          1991   \n",
       "2          3      6       770.0              0      1933             0   \n",
       "3          5      7      1050.0            910      1965             0   \n",
       "4          3      8      1680.0              0      1987             0   \n",
       "\n",
       "   zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0    98178  47.5112 -122.257           1340        5650  \n",
       "1    98125  47.7210 -122.319           1690        7639  \n",
       "2    98028  47.7379 -122.233           2720        8062  \n",
       "3    98136  47.5208 -122.393           1360        5000  \n",
       "4    98074  47.6168 -122.045           1800        7503  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = housing_df.drop(columns=[\"price\"])\n",
    "y = housing_df[\"price\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    221900.0\n",
       "1    538000.0\n",
       "2    180000.0\n",
       "3    604000.0\n",
       "4    510000.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{admonition} Attention\n",
    ":class: important\n",
    "To a machine, column names (features) have no meaning. Only feature values and how they vary across examples mean something. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Alternative terminology for examples, features, targets, and training\n",
    "\n",
    "- **examples** = rows = samples = records = instances \n",
    "- **features** = inputs = predictors = explanatory variables = regressors = independent variables = covariates\n",
    "- **targets** = outputs = outcomes = response variable = dependent variable = labels (if categorical).\n",
    "- **training** = learning = fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{seealso} \n",
    "Check out [the MDS terminology document](https://ubc-mds.github.io/resources_pages/terminology/). \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised learning vs. Unsupervised learning\n",
    "\n",
    "In **supervised learning**, training data comprises a set of features ($X$) and their corresponding targets ($y$). We wish to find a **model function $f$** that relates $X$ to $y$. Then use that model function **to predict the targets** of new examples. \n",
    "\n",
    "<img src=\"img/sup-learning.png\" height=\"900\" width=\"900\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In **unsupervised learning** training data consists of observations ($X$) **without any corresponding targets**. Unsupervised learning could be used to **group similar things together** in $X$ or to provide **concise summary** of the data. We'll learn more about this topic in later videos.\n",
    "\n",
    "<img src=\"img/unsup-learning.png\" alt=\"\" height=\"900\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification vs. Regression \n",
    "In supervised machine learning, there are two main kinds of learning problems based on what they are trying to predict.\n",
    "- **Classification problem**: predicting among two or more discrete classes\n",
    "    - Example1: Predict whether a patient has a liver disease or not\n",
    "    - Example2: Predict whether a student would get an A+ or not in quiz2.  \n",
    "- **Regression problem**: predicting a continuous value\n",
    "    - Example1: Predict housing prices \n",
    "    - Example2: Predict a student's score in quiz2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/classification-vs-regression.png\" height=\"1500\" width=\"1500\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_experience</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>lab1</th>\n",
       "      <th>lab2</th>\n",
       "      <th>lab3</th>\n",
       "      <th>lab4</th>\n",
       "      <th>quiz1</th>\n",
       "      <th>quiz2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>not A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>not A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ml_experience  class_attendance  lab1  lab2  lab3  lab4  quiz1   quiz2\n",
       "0              1                 1    92    93    84    91     92      A+\n",
       "1              1                 0    94    90    80    83     91  not A+\n",
       "2              0                 0    78    85    83    80     80  not A+\n",
       "3              0                 1    91    94    92    91     89      A+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quiz2 classification toy data\n",
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "classification_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_experience</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>lab1</th>\n",
       "      <th>lab2</th>\n",
       "      <th>lab3</th>\n",
       "      <th>lab4</th>\n",
       "      <th>quiz1</th>\n",
       "      <th>quiz2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ml_experience  class_attendance  lab1  lab2  lab3  lab4  quiz1  quiz2\n",
       "0              1                 1    92    93    84    91     92     90\n",
       "1              1                 0    94    90    80    83     91     84\n",
       "2              0                 0    78    85    83    80     80     82\n",
       "3              0                 1    91    94    92    91     89     92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quiz2 regression toy data\n",
    "regression_df = pd.read_csv(\"data/quiz2-grade-toy-regression.csv\")\n",
    "regression_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2.1.1: $X$ and $y$  \n",
    "1. How many examples and features are there in the housing price data above? You can use `df.shape` to get number of rows and columns in a dataframe. \n",
    "2. For each of the following examples what would be the relevant features and what would be the target?\n",
    "    1. Credit risk assessment\n",
    "    2. Sentiment analysis\n",
    "    2. Fraud detection \n",
    "    3. Face recognition \n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2.1.2: Supervised vs. unsupervised \n",
    "\n",
    "Which of these are examples of supervised learning?\n",
    "\n",
    "1. Finding groups of similar properties in a real estate data set.\n",
    "2. Predicting real estate prices based on house features like number of rooms, learning from past sales as examples.\n",
    "3. Grouping articles on different topics from different news sources (something like Google News app). \n",
    "4. Detecting credit card fraud based on examples of fraudulent and non-fraudulent transactions.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1.1.2: Solutions!\n",
    ":class: tip, dropdown\n",
    "1. Unsupervised \n",
    "2. Supervised\n",
    "3. Unsupervised\n",
    "4. Supervised\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2.1.3: Classification vs. Regression\n",
    "\n",
    "Which of these are examples of classification and which ones are of regression?\n",
    "\n",
    "1. Predicting the price of a house based on features such as number of bedrooms and the year built.\n",
    "2. Predicting if a house will sell or not based on features like the price of the house, number of rooms, etc.\n",
    "3. Predicting your grade in 571 based on past grades.\n",
    "4. Predicting whether you should bicycle tomorrow or not based on the weather forecast.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1.1.3: Solutions!\n",
    ":class: tip, dropdown\n",
    "1. Regression  \n",
    "2. Classification \n",
    "3. Regression\n",
    "4. Classification\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised Learning (Reminder)\n",
    "\n",
    "- Training data $\\rightarrow$ Machine learning algorithm $\\rightarrow$ ML model \n",
    "- Unseen test data + ML model $\\rightarrow$ predictions\n",
    "\n",
    "\n",
    "```{image} img/sup-learning.png\n",
    ":alt: ML examples\n",
    ":class: bg-primary mb-1\n",
    ":width: 1200px\n",
    ":align: center\n",
    "```\n",
    "<!-- <center>\n",
    "<img src=\"img/sup-learning.png\" height=\"1200\" width=\"1200\"> \n",
    "</center> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baseline intuition\n",
    "\n",
    "- Baseline: A simple machine learning algorithm based on simple rules of thumb. For example, \n",
    "    - most frequent baseline: always predicts the most frequent label in the training set. \n",
    "- Baselines provide a way to sanity check your machine learning model.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DummyClassifier` \n",
    "\n",
    "Let's look at an example of using `DummyClassifier`, `sklearn`'s baseline model for classification.  \n",
    "\n",
    "Building any kind of machine learning model using `sklearn`, including the baseline model, has the following steps. \n",
    "\n",
    "1. Read the data\n",
    "2. Create $X$ and $y$\n",
    "3. Create a classifier object\n",
    "4. `fit` the classifier\n",
    "5. `predict` on new examples\n",
    "6. `score` the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Reading the data\n",
    "\n",
    "Let's use our quiz2 grade prediction toy classification dataset as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "classification_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Create $X$ and $y$\n",
    "\n",
    "- $X$ &rarr; Feature vectors\n",
    "- $y$ &rarr; Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create a classifier object\n",
    "\n",
    "- `import` the appropriate classifier \n",
    "- Create an object of the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# scikit-learn DummyClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create a classifier object\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### `fit` the classifier\n",
    "\n",
    "- The \"learning\" is carried out when we call `fit` on the classifier object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# fit the classifier\n",
    "dummy_clf.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `predict` the target of given examples\n",
    "\n",
    "- We can predict the target of examples by calling `predict` on the classifier object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# predict using the learner classifier\n",
    "dummy_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "classification_df[\"quiz2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `score` your model\n",
    "\n",
    "- How do you know how well your model is doing?\n",
    "- For classification problems, by default, `score` gives the **accuracy** of the model, i.e., proportion of correctly predicted targets.  \n",
    "\n",
    "    $accuracy = \\frac{\\text{correct predictions}}{\\text{total examples}}$\n",
    "    \n",
    "- Sometimes you will also see people reporting **error**, which is usually $1 - accuracy$ \n",
    "- `score` \n",
    "    - calls `predict` on `X` \n",
    "    - compares predictions with `y` (true targets)\n",
    "    - returns the accuracy in case of classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy of the model on the training data: %0.3f\" % (dummy_clf.score(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The error of the model on the training data: %0.3f\" % (1 - dummy_clf.score(X, y))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `fit`, `predict` , and `score` summary\n",
    "\n",
    "Here is the general pattern when we build ML models using `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create `X` and `y` from the given data\n",
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]\n",
    "\n",
    "# Create a class object\n",
    "clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Train/fit the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Assess the model\n",
    "clf.score(X, y)\n",
    "\n",
    "# Predict on some new data using the trained model\n",
    "new_examples = [[0, 1, 92, 90, 95, 93, 92], [1, 1, 92, 93, 94, 92]]\n",
    "clf.predict(new_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```{note} \n",
    "You'll be exploring dummy classifier in your lab!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `DummyRegressor`\n",
    "\n",
    "You can also do the same thing for regression problems using `DummyRegressor`. Let's build a regression baseline model using `sklearn`. The `fit` and `predict` paradigms similar to classification. The `score`  method in the context of regression returns somethings called [$R^2$ score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score). (More on this in DSCI 573.)     \n",
    "    - The maximum $R^2$ is 1 for perfect predictions. \n",
    "    - For `DummyRegressor` it returns the mean of the `y` values.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Create `X` and `y` from the given data\n",
    "X = regression_df.drop(columns=[\"quiz2\"])\n",
    "y = regression_df[\"quiz2\"]\n",
    "\n",
    "# Create a class object\n",
    "reg = DummyRegressor()\n",
    "\n",
    "# Train/fit the model\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Assess the model\n",
    "reg.score(X, y)\n",
    "\n",
    "# Predict on some new data using the trained model\n",
    "new_examples = [[0, 1, 92, 90, 95, 93, 92], [1, 1, 92, 93, 94, 92]]\n",
    "reg.predict(new_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2.2.1\n",
    "1. Order the steps below to build ML models using `sklearn`. \n",
    "    a. `score` to evaluate the performance of a given model\n",
    "    b. `predict` on new examples \n",
    "    c. Creating a model instance\n",
    "    d. Creating `X` and `y` \n",
    "    e. `fit`\n",
    "2. `predict` takes only `X` as argument whereas `fit` and `score` take both `X` and `y` as arguments. True or False. \n",
    "3. Have you ever played [20-questions game](https://en.wikipedia.org/wiki/Twenty_questions)? If yes, think about how do you decide what question to ask next? \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2.2.1: Solutions!\n",
    ":class: tip, dropdown\n",
    "\n",
    "- Steps to build ML models using `sklearn`: d, c, e, a, b          \n",
    "- True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.3 Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Writing a traditional program to predict quiz2 grade\n",
    "\n",
    "- Can we do better than the baseline? \n",
    "- Forget about ML for a second. If you are asked to write a program to predict whether a student gets an A+ or not in quiz2, how would you go for it?  \n",
    "- For simplicity, let's binarize the feature values. \n",
    "\n",
    "```{image} img/quiz2-grade-toy.png\n",
    ":alt: quiz2-grade-toy\n",
    ":class: bg-primary mb-1\n",
    ":width: 1000px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "<!-- <img src=\"img/quiz2-grade-toy.png\" height=\"1000\" width=\"1000\">  -->\n",
    "\n",
    "- Is there a pattern that distinguishes yes's from no's and what does the pattern say about today? \n",
    "- How about a rule-based algorithm with a number of *if else* statements?  \n",
    "    ```\n",
    "    if class_attendance == 1 and quiz1 == 1:\n",
    "        quiz2 == \"A+\"\n",
    "    elif class_attendance == 1 and lab3 == 1 and lab4 == 1:\n",
    "        quiz2 == \"A+\"\n",
    "    ...\n",
    "    ```\n",
    "- How many possible rule combinations there could be with the given 7 binary features? \n",
    "    - Gets unwieldy pretty quickly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision tree algorithm \n",
    "\n",
    "- A machine learning algorithm to derive such rules from data in a principled way.  \n",
    "- Have you ever played [20-questions game](https://en.wikipedia.org/wiki/Twenty_questions)? Decision trees are based on the same idea! \n",
    "- Let's `fit` a decision tree using `scikit-learn` and `predict` with it.\n",
    "- Recall that `scikit-learn` uses the term `fit` for training or learning and uses `predict` for prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building decision trees with `sklearn`\n",
    "\n",
    "Let's binarize our toy dataset for simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]\n",
    "\n",
    "X_binary = X.copy()\n",
    "columns = [\"lab1\", \"lab2\", \"lab3\", \"lab4\", \"quiz1\"]\n",
    "for col in columns:\n",
    "    X_binary[col] = X_binary[col].apply(lambda x: 1 if x >= 90 else 0)\n",
    "X_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `DummyClassifier` on quiz2 grade prediction toy dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_binary, y)\n",
    "dummy_clf.score(X_binary, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### `DecisionTreeClassifier` on quiz2 grade prediction toy dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a decision tree\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit a decision tree\n",
    "model.fit(X_binary, y)\n",
    "\n",
    "# Assess the model\n",
    "model.score(X_binary, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree classifier is giving much higher accuracy than the dummy classifier. That's good news! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's visualize the learned model\n",
    "display_tree(X_binary.columns, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some terminology related to trees \n",
    "\n",
    "Here is a commonly used terminology in a typical representation of decision trees. \n",
    "\n",
    "**A root node**\n",
    ": represents the first condition to check or question to ask\n",
    "\n",
    "**A branch**\n",
    ": connects a node (condition) to the next node (condition) in the tree. Each branch typically represents either true or false. \n",
    "\n",
    "**An internal node** \n",
    ": represents conditions within the tree\n",
    "\n",
    "**A leaf node**\n",
    ": represents the predicted class/value when the path from root to the leaf node is followed. \n",
    "\n",
    "**Tree depth**\n",
    ": The number of edges on the path from the root node to the farthest away leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does `predict` work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "new_example = np.array([[0, 1, 0, 0, 1, 1, 1]])\n",
    "pd.DataFrame(data=new_example, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=new_example, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "display_tree(X_binary.columns, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# What't the prediction for the new example?\n",
    "model.predict(new_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In summary, given a learned tree and a test example, during prediction time,  \n",
    "- Start at the top of the tree. Ask binary questions at each node and follow the appropriate path in the tree. Once you are at a leaf node, you have the prediction. \n",
    "- Note that the model only considers the features which are in the learned tree and ignores all other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (optional) How does `fit` work? \n",
    "\n",
    "- Which features are most useful for classification? \n",
    "- Minimize **impurity** at each question\n",
    "- Common criteria to minimize impurity: [gini index](https://scikit-learn.org/stable/modules/tree.html#classification-criteria), information gain, cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Warning \n",
    ":class: warning \n",
    "We won't go through **how** it does this - that's CPSC 340. But it's worth noting that it support two types of inputs: \n",
    "    1. Categorical (e.g., Yes/No or more options, as shown in the tree above)\n",
    "    2. Numeric (a number)In the numeric case, the decision tree algorithm also picks the _threshold_. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision trees with continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Trees with continuous features\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "display_tree(X.columns, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision tree Regressor <a name=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also use decision tree algorithm for regression. \n",
    "- Instead of gini, we use [some other criteria](https://scikit-learn.org/stable/modules/tree.html#mathematical-formulation) for splitting. A common one is mean squared error (MSE). (More on this in the next block.)\n",
    "- `scikit-learn` supports regression using decision trees with `DecisionTreeRegressor` \n",
    "    - `fit` and `predict` paradigms similar to classification\n",
    "    - `score` returns somethings called [$R^2$ score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score). (More on this in 573.)     \n",
    "        - The maximum $R^2$ is 1 for perfect predictions. \n",
    "        - It can be negative which is very bad (worse than `DummyRegressor`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "regression_df = pd.read_csv(\"data/quiz2-grade-toy-regression.csv\")\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = regression_df.drop([\"quiz2\"], axis=1)\n",
    "y = regression_df[\"quiz2\"]\n",
    "\n",
    "depth = 4\n",
    "reg_model = DecisionTreeRegressor(max_depth=depth)\n",
    "reg_model.fit(X, y)\n",
    "\n",
    "# display_tree(X.columns, reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reg_model.predict(X)\n",
    "regression_df[\"predicted_quiz2\"] = reg_model.predict(X)\n",
    "print(\"R^2 score on the training data: %0.3f\\n\\n\" % (reg_model.score(X, y)))\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓❓ Questions for you to ponder on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2.3.1\n",
    "1. Should change in features (i.e., binarizing features above) change `DummyClassifier` predictions? \n",
    "2. When you play 20-questions game, how do you pick the next question to ask?\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2.3.2 True or False \n",
    "1. For the decision tree algorithm to work, the feature values must be numeric.  \n",
    "2. For the decision tree algorithm to work, the target values must be numeric.\n",
    "3. The decision tree algorithm creates balanced decision trees. \n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.4 More terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and hyperparameters\n",
    "\n",
    "**Parameters**\n",
    ": When you call `fit`, a bunch of values get set, like the features to split on and split thresholds. These are called **parameters**. These are automatically learned by the algorithm during training.\n",
    "\n",
    "**Hyperparameters**\n",
    ": Even before calling `fit` on a specific data set, we can set some \"knobs\" that control the learning. These are called **hyperparameters**. These are specified based on: expert knowledge, heuristics, or systematic/automated optimization (more on that in the coming lectures)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `max_depth` hyperparameter of decision trees\n",
    "\n",
    "- `DecisionTreeClassifier` has a number of hyperparameters. \n",
    "- Let's explore at the `max_depth` hyperparameter, which controls the **depth** of the decision tree, which is the length of the longest path from the tree root to a leaf. (You'll learn about the tree data structure in 512.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Attention\n",
    ":class: important\n",
    "In `sklearn` hyperparameters are set in the constructor. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=1)\n",
    "model.fit(X, y)\n",
    "display_tree(X.columns, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Decision stump**\n",
    ": A decision tree with only one split (depth=1) is called a **decision stump**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    max_depth=4\n",
    ")  # Let's try another value for the hyperparameter\n",
    "model.fit(X, y)\n",
    "display_tree(X.columns, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{seealso}\n",
    "See [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for other hyperparameters of a tree.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision boundary \n",
    "\n",
    "What do we do with learned models? So far we have been using them to predict the class of a new instance. Another way to think about them is to ask: what sort of test examples will the model classify as positive, and what sort will it classify as negative? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: quiz 2 grade prediction \n",
    "\n",
    "For visualization, let's consider a subset of the data with only two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_subset = X[[\"lab4\", \"quiz1\"]]\n",
    "X_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision boundary for `max_depth=1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 1  # decision stump\n",
    "model = DecisionTreeClassifier(max_depth=depth)\n",
    "model.fit(X_subset, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model, X_subset, y, x_label=\"lab1\", y_label=\"quiz1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume geometric view of the data. (More on this in lecture 3.) Here, the red region corresponds to \"not A+\" class and blue region corresponds to \"A+\" class. And there is a line separating the red region and the blue region which is called the **decision boundary** of the model. In our current model, this decision boundary is created by asking one question `lab4 <= 84.5`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision boundary for `max_depth=3` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=3)\n",
    "model.fit(X_subset, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model, X_subset, y, x_label=\"lab1\", y_label=\"quiz1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary, i.e., the model gets a bit more complicated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision boundary for `max_depth=5` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_subset, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model, X_subset, y, x_label=\"lab1\", y_label=\"quiz1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary, i.e., the model gets even more complicated with `max_depth=5`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example 2: Predicting country using the longitude and latitude \n",
    "\n",
    "Imagine that you are given longitude and latitude of some border cities of USA and Canada along with which country they belong to. Using this training data, you are supposed to come up with a classification model to predict whether a given longitude and latitude combination is in the USA or Canada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### US Canada cities data\n",
    "df = pd.read_csv(\"data/canada_usa_cities.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"longitude\", \"latitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"country\"]\n",
    "y_bin = y.replace(\"USA\", 0)\n",
    "y_bin = y_bin.replace(\"Canada\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(X.iloc[:, 0], X.iloc[:, 1], y)\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "##### Real boundary between Canada and USA\n",
    "\n",
    "In real life we know what's the boundary between USA and Canada. \n",
    "\n",
    "```{image} img/canada-us-border.jpg\n",
    ":alt: canada-us-border\n",
    ":class: bg-primary mb-1\n",
    ":width: 500px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "<!-- <img src=\"img/canada-us-border.jpg\" height=\"500\" width=\"500\">  -->\n",
    "\n",
    "[Source](https://sovereignlimits.com/blog/u-s-canada-border-history-disputes)\n",
    "\n",
    "Here we want to pretend that we do not know this boundary and we want to infer this boundary based on the limited training examples given to us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=1)\n",
    "model.fit(X, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    height=6,\n",
    "    width=16,\n",
    "    eps=10,\n",
    "    x_label=\"longitude\",\n",
    "    y_label=\"latitude\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    height=6,\n",
    "    width=16,\n",
    "    eps=10,\n",
    "    x_label=\"longitude\",\n",
    "    y_label=\"latitude\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_tree_progressive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments and summary\n",
    "\n",
    "What did we learn today? \n",
    "\n",
    "- There is a lot of terminology and jargon used in ML. Some of the basic \n",
    "terminology includes:\n",
    "    - Features, target, examples, training\n",
    "    - Classification, regression    \n",
    "    - Accuracy and error    \n",
    "    - Parameters and hyperparameters\n",
    "    - Decision boundary \n",
    "- Supervised vs. Unsupervised machine learning \n",
    "    - Supervised machine learning is about function approximation whereas unsupervised machine learning is about concisely describing the data.   \n",
    "    - There are two major types of supervised machine learning problems: classification and regression.    \n",
    "- Baselines\n",
    "    - Baselines serve as reference points in ML workflow. \n",
    "- Decision trees    \n",
    "    - are classifiers that make predictions by sequentially looking at features and checking whether they are above/below a threshold\n",
    "    - learn a hierarchy of if/else questions, similar to questions you might ask in a 20-questions game.       \n",
    "    - learn axis-aligned decision boundaries (vertical and horizontal lines with 2 features)    \n",
    "    - One way to control the complexity of decision tree models is by using the depth hyperparameter (`max_depth` in `sklearn`). \n",
    "    \n",
    "- **Decision boundaries** provide a way to visualize what sort of examples will be classified as positive and negative.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-logging-off.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
