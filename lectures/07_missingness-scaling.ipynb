{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CPSC 330 Lecture 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lecture plan\n",
    "\n",
    "- ðŸ‘‹\n",
    "- **Turn on recording**\n",
    "- Announcements\n",
    "- Missing data (15 min)\n",
    "- Feature scaling (25 min)\n",
    "- Break (5 min)\n",
    "- Putting it all together with `ColumnTransformer` (20 min)\n",
    "- Trying a bunch of classifiers (10 min)\n",
    "- Summary (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV \n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing data (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we'll continue with the census data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('data/adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed last time, we'll drop the `education` column because it's already been ordinally encoded in `education.num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = census.drop(columns=[\"education\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_train, census_test = train_test_split(census, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt  education.num marital.status         occupation  \\\n",
       "0   90         ?   77053              9        Widowed                  ?   \n",
       "1   82   Private  132870              9        Widowed    Exec-managerial   \n",
       "2   66         ?  186061             10        Widowed                  ?   \n",
       "3   54   Private  140359              4       Divorced  Machine-op-inspct   \n",
       "4   41   Private  264663             10      Separated     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "0  Not-in-family  White  Female             0          4356              40   \n",
       "1  Not-in-family  White  Female             0          4356              18   \n",
       "2      Unmarried  Black  Female             0          4356              40   \n",
       "3      Unmarried  White  Female             0          3900              40   \n",
       "4      Own-child  White  Female             0          3900              40   \n",
       "\n",
       "  native.country income  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_train.sort_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see we have a bunch of missing values, where presumably the person did not answer that question on the census.\n",
    "- Interestingly, these were not picked up: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26048 entries, 17064 to 19966\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             26048 non-null  int64 \n",
      " 1   workclass       26048 non-null  object\n",
      " 2   fnlwgt          26048 non-null  int64 \n",
      " 3   education.num   26048 non-null  int64 \n",
      " 4   marital.status  26048 non-null  object\n",
      " 5   occupation      26048 non-null  object\n",
      " 6   relationship    26048 non-null  object\n",
      " 7   race            26048 non-null  object\n",
      " 8   sex             26048 non-null  object\n",
      " 9   capital.gain    26048 non-null  int64 \n",
      " 10  capital.loss    26048 non-null  int64 \n",
      " 11  hours.per.week  26048 non-null  int64 \n",
      " 12  native.country  26048 non-null  object\n",
      " 13  income          26048 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "census_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Everything is non-null because the missing values were encoded as the string \"?\" instead of an actual NaN in Python.\n",
    "- We saw those last class, where \"?\" was a category generated by OHE.\n",
    "- Let's change them to actual nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77053</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186061</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt  education.num marital.status         occupation  \\\n",
       "0   90       NaN   77053              9        Widowed                NaN   \n",
       "1   82   Private  132870              9        Widowed    Exec-managerial   \n",
       "2   66       NaN  186061             10        Widowed                NaN   \n",
       "3   54   Private  140359              4       Divorced  Machine-op-inspct   \n",
       "4   41   Private  264663             10      Separated     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "0  Not-in-family  White  Female             0          4356              40   \n",
       "1  Not-in-family  White  Female             0          4356              18   \n",
       "2      Unmarried  Black  Female             0          4356              40   \n",
       "3      Unmarried  White  Female             0          3900              40   \n",
       "4      Own-child  White  Female             0          3900              40   \n",
       "\n",
       "  native.country income  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4  United-States  <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_nan = census_train.replace('?', np.NaN)\n",
    "df_test_nan  = census_test.replace( '?', np.NaN)\n",
    "\n",
    "df_train_nan.sort_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26048 entries, 17064 to 19966\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             26048 non-null  int64 \n",
      " 1   workclass       24600 non-null  object\n",
      " 2   fnlwgt          26048 non-null  int64 \n",
      " 3   education.num   26048 non-null  int64 \n",
      " 4   marital.status  26048 non-null  object\n",
      " 5   occupation      24595 non-null  object\n",
      " 6   relationship    26048 non-null  object\n",
      " 7   race            26048 non-null  object\n",
      " 8   sex             26048 non-null  object\n",
      " 9   capital.gain    26048 non-null  int64 \n",
      " 10  capital.loss    26048 non-null  int64 \n",
      " 11  hours.per.week  26048 non-null  int64 \n",
      " 12  native.country  25573 non-null  object\n",
      " 13  income          26048 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_nan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can see the null values, and likely these would be picked out by pandas profiler.\n",
    "  - Note: we'll address null values in the features, not in the targets.\n",
    "- So, how should we address these?\n",
    "- Disclaimer: we will only cover this in a super simplistic way.\n",
    "- See STAT courses for a proper treatment of this topic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gotta drop 'em all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nan = df_train_nan.drop(columns=['income'])\n",
    "X_test_nan  = df_test_nan.drop(columns=['income'])\n",
    "y_train = df_train_nan['income']\n",
    "y_test = df_test_nan['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24144, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nan.dropna(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, we dropped about 2000 rows.\n",
    "- We'd need to do the same in our test set.\n",
    "- But what if we get a missing value in deployment?\n",
    "- And furthermore, what if the missing values don't occur at random and we're systematically dropping certain data?\n",
    "- This is not a great solution, especially if there's a lot of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nan.dropna(axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One can also drop all _columns_ with missing values using `axis=1`. \n",
    "- This generally throws away a lot of information, because you lose a whole column just for 1 missing value.\n",
    "- But I might drop a column if it's 99.9% missing values, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imputation means inventing values for the missing data.\n",
    "- The strategies are different for numeric vs. categorical.\n",
    "- In this dataset it turns out we only have missing values in the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This imputer is another transformer, like the other ones we've seen (`CountVectorizer`, `OrdinalEncoder`, `OneHotEncoder`).\n",
    "- The \"most_frequent\" strategy puts in the most frequent value seen in that column.\n",
    "- There are also strategies for numeric variables, like taking the mean or median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'fnlwgt', 'education.num', 'capital.gain', \n",
    "                    'capital.loss', 'hours.per.week']\n",
    "categorical_features = ['workclass', 'marital.status', 'occupation', \n",
    "                        'relationship', 'race', 'sex', 'native.country']\n",
    "target_column = 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.fit(X_train_nan[categorical_features]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp_cat = pd.DataFrame(imp.transform(X_train_nan[categorical_features]),\n",
    "                           columns=categorical_features, index=X_train_nan.index)\n",
    "X_test_imp_cat = pd.DataFrame(imp.transform(X_test_nan[categorical_features]),\n",
    "                           columns=categorical_features, index=X_test_nan.index)\n",
    "\n",
    "X_train_imp = X_train_nan.copy()\n",
    "X_train_imp.update(X_train_imp_cat)\n",
    "\n",
    "X_test_imp = X_test_nan.copy()\n",
    "X_test_imp.update(X_test_imp_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the missing values filled in. Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77053</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186061</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt  education.num marital.status         occupation  \\\n",
       "0   90       NaN   77053              9        Widowed                NaN   \n",
       "1   82   Private  132870              9        Widowed    Exec-managerial   \n",
       "2   66       NaN  186061             10        Widowed                NaN   \n",
       "3   54   Private  140359              4       Divorced  Machine-op-inspct   \n",
       "4   41   Private  264663             10      Separated     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "0  Not-in-family  White  Female             0          4356              40   \n",
       "1  Not-in-family  White  Female             0          4356              18   \n",
       "2      Unmarried  Black  Female             0          4356              40   \n",
       "3      Unmarried  White  Female             0          3900              40   \n",
       "4      Own-child  White  Female             0          3900              40   \n",
       "\n",
       "  native.country  \n",
       "0  United-States  \n",
       "1  United-States  \n",
       "2  United-States  \n",
       "3  United-States  \n",
       "4  United-States  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nan.sort_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>Private</td>\n",
       "      <td>77053</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>Private</td>\n",
       "      <td>186061</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt  education.num marital.status         occupation  \\\n",
       "0   90   Private   77053              9        Widowed     Prof-specialty   \n",
       "1   82   Private  132870              9        Widowed    Exec-managerial   \n",
       "2   66   Private  186061             10        Widowed     Prof-specialty   \n",
       "3   54   Private  140359              4       Divorced  Machine-op-inspct   \n",
       "4   41   Private  264663             10      Separated     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "0  Not-in-family  White  Female             0          4356              40   \n",
       "1  Not-in-family  White  Female             0          4356              18   \n",
       "2      Unmarried  Black  Female             0          4356              40   \n",
       "3      Unmarried  White  Female             0          3900              40   \n",
       "4      Own-child  White  Female             0          3900              40   \n",
       "\n",
       "  native.country  \n",
       "0  United-States  \n",
       "1  United-States  \n",
       "2  United-States  \n",
       "3  United-States  \n",
       "4  United-States  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imp.sort_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into any detail about methods of imputation, but you can consider the different approaches as hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill value\n",
    "\n",
    "- By the way, another option would be to just leave in the \"?\" and have this be its own category for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleImputer(strategy='constant', fill_value=\"?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I won't get too deep into this in this course. \n",
    "- We can just say what we always say - treat it as a hyperparameter unless you have a better idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline\n",
    "\n",
    "Let's build a Pipeline with what we have so far for categorical features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('imputation', SimpleImputer(strategy='most_frequent')),\n",
    "                 ('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "                 ('lr', LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we have a Pipeline with 3 stages: 2 transformers followed by a classifier.\n",
    "- Now we can go back to that image from Lecture 5 and it's more appropriate:\n",
    "\n",
    "<img src=\"img/pipeline.png\" width=\"700\">\n",
    "\n",
    "[Source](https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/#18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>0.813244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888231</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.808829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.895017</td>\n",
       "      <td>0.016058</td>\n",
       "      <td>0.805950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.909701</td>\n",
       "      <td>0.015221</td>\n",
       "      <td>0.819159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883047</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>0.815512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.880267    0.015519    0.813244\n",
       "1  0.888231    0.014595    0.808829\n",
       "2  0.895017    0.016058    0.805950\n",
       "3  0.909701    0.015221    0.819159\n",
       "4  0.883047    0.015392    0.815512"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(pipe, X_train_nan[categorical_features], y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Great, so this all works, but we only used the categorical features.\n",
    "- Later today we'll see how to combine everything nicely with `ColumnTransformer`.\n",
    "- But first, one more thing: preprocessing of the numeric variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling (25 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>20</td>\n",
       "      <td>110998</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>22</td>\n",
       "      <td>263670</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>51</td>\n",
       "      <td>335997</td>\n",
       "      <td>9</td>\n",
       "      <td>4386</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>53</td>\n",
       "      <td>111939</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>52</td>\n",
       "      <td>51048</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>48</td>\n",
       "      <td>70668</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>35</td>\n",
       "      <td>340018</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28030</th>\n",
       "      <td>26</td>\n",
       "      <td>373553</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>28</td>\n",
       "      <td>155621</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>40</td>\n",
       "      <td>151294</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education.num  capital.gain  capital.loss  hours.per.week\n",
       "17064   20  110998             10             0             0              30\n",
       "18434   22  263670              9             0             0              80\n",
       "3294    51  335997              9          4386             0              55\n",
       "31317   53  111939             13             0             0              35\n",
       "4770    52   51048             13             0             0              55\n",
       "...    ...     ...            ...           ...           ...             ...\n",
       "28636   48   70668              9             0             0              50\n",
       "17730   35  340018              6             0             0              38\n",
       "28030   26  373553             10             0             0              42\n",
       "15725   28  155621              3             0             0              40\n",
       "19966   40  151294              9             0             0              48\n",
       "\n",
       "[26048 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imp[numeric_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a model using only these features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.114391\n",
       "score_time     0.011969\n",
       "test_score     0.799217\n",
       "train_score    0.799505\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "pd.DataFrame(cross_validate(lr, X_train_imp[numeric_features], y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so `DummyClassifier` gets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7605190417690417"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DummyClassifier(strategy='prior').fit(None, y_train).score(None, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And here we do a few percent better.\n",
    "- But let's look at the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train_imp[numeric_features], y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.007233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>-0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education.num</th>\n",
       "      <td>-0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital.gain</th>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital.loss</th>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours.per.week</th>\n",
       "      <td>-0.007883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Coefficient\n",
       "age               -0.007233\n",
       "fnlwgt            -0.000004\n",
       "education.num     -0.001697\n",
       "capital.gain       0.000337\n",
       "capital.loss       0.000785\n",
       "hours.per.week    -0.007883"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=lr.coef_[0], index=numeric_features, columns=['Coefficient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What we see here is a very small coefficient for `fnlwgt` (description of this feature [here](https://www.kaggle.com/uciml/adult-census-income), I couldn't quite decipher it).\n",
    "- Why is this coefficient so small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26048.000000</td>\n",
       "      <td>2.604800e+04</td>\n",
       "      <td>26048.000000</td>\n",
       "      <td>26048.000000</td>\n",
       "      <td>26048.000000</td>\n",
       "      <td>26048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.586686</td>\n",
       "      <td>1.892295e+05</td>\n",
       "      <td>10.070485</td>\n",
       "      <td>1075.695754</td>\n",
       "      <td>87.629991</td>\n",
       "      <td>40.433239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.619181</td>\n",
       "      <td>1.050005e+05</td>\n",
       "      <td>2.572231</td>\n",
       "      <td>7334.297499</td>\n",
       "      <td>404.192112</td>\n",
       "      <td>12.346313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175830e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.777850e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.368852e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.366120e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "count  26048.000000  2.604800e+04   26048.000000  26048.000000  26048.000000   \n",
       "mean      38.586686  1.892295e+05      10.070485   1075.695754     87.629991   \n",
       "std       13.619181  1.050005e+05       2.572231   7334.297499    404.192112   \n",
       "min       17.000000  1.376900e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.175830e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.777850e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.368852e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.366120e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours.per.week  \n",
       "count    26048.000000  \n",
       "mean        40.433239  \n",
       "std         12.346313  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nan.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Answer: because the values are so big (avg = 200,000)\n",
    "- And what if these values happened to be even larger? Or what if capital gain/loss was measured in thousands of dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mod = X_train_imp[numeric_features].copy()\n",
    "X_train_mod[\"capital.gain\"] /= 1000\n",
    "X_train_mod[\"capital.loss\"] /= 1000\n",
    "X_train_mod[\"fnlwgt\"] *= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>20</td>\n",
       "      <td>110998000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>22</td>\n",
       "      <td>263670000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>51</td>\n",
       "      <td>335997000</td>\n",
       "      <td>9</td>\n",
       "      <td>4.386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>53</td>\n",
       "      <td>111939000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>52</td>\n",
       "      <td>51048000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "17064   20  110998000             10         0.000           0.0   \n",
       "18434   22  263670000              9         0.000           0.0   \n",
       "3294    51  335997000              9         4.386           0.0   \n",
       "31317   53  111939000             13         0.000           0.0   \n",
       "4770    52   51048000             13         0.000           0.0   \n",
       "\n",
       "       hours.per.week  \n",
       "17064              30  \n",
       "18434              80  \n",
       "3294               55  \n",
       "31317              35  \n",
       "4770               55  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.056197\n",
       "score_time     0.012094\n",
       "test_score     0.760519\n",
       "train_score    0.760519\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "pd.DataFrame(cross_validate(lr, X_train_mod, y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now our train & test scores went down to basically `DummyClassifier` level!\n",
    "- But what is up with that, these units are arbitrary to begin with!!\n",
    "- BTW, decision trees don't have this problem because they're only about thresholds, rather than crunching the actual number.\n",
    "  - [Great post on Piazza](https://piazza.com/class/kb2e6nwu3uj23?cid=256) pointing out something similar with the spacing in ordinal encodings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7707694308794502"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "cross_val_score(dt, X_train_imp[numeric_features], y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7707694308794502"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "cross_val_score(dt, X_train_mod, y_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But this problem affects plenty of ML methods.\n",
    "- So it would be nice to just take care of this issue.\n",
    "- The general approach is to rescale the features.\n",
    "- Two specific approaches we'll cover are standardization and normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Approach | What it does | How to update $X$ (but see below!) | sklearn implementation | \n",
    "|---------|------------|-----------------------|----------------|\n",
    "| normalization | sets range to $[0,1]$   | `X -= np.min(X,axis=0)`<br>`X /= np.max(X,axis=0)`  | [`MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "| standardization | sets sample mean to $0$, s.d. to $1$   | `X -= np.mean(X,axis=0)`<br>`X /=  np.std(X,axis=0)` | [`StandardScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) |\n",
    "\n",
    "There are all sorts of articles on this; see, e.g. [here](http://www.dataminingblog.com/standardization-vs-normalization/) and [here](https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these scaling methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_imp[numeric_features]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.36476947, -0.74507317, -0.02740291, -0.14666932, -0.21680698,\n",
       "        -0.84506515],\n",
       "       [-1.21791495,  0.70896709, -0.41617802, -0.14666932, -0.21680698,\n",
       "         3.20480459],\n",
       "       [ 0.91147565,  1.39780572, -0.41617802,  0.45135445, -0.21680698,\n",
       "         1.17986972],\n",
       "       ...,\n",
       "       [-0.9242059 ,  1.75548713, -0.02740291, -0.14666932, -0.21680698,\n",
       "         0.12690359],\n",
       "       [-0.77735138, -0.32008602, -2.74882863, -0.14666932, -0.21680698,\n",
       "        -0.0350912 ],\n",
       "       [ 0.10377577, -0.36129614, -0.41617802, -0.14666932, -0.21680698,\n",
       "         0.61288796]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_train_imp[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>-1.364769</td>\n",
       "      <td>-0.745073</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.845065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>-1.217915</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>3.204805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>0.911476</td>\n",
       "      <td>1.397806</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>0.451354</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>1.058330</td>\n",
       "      <td>-0.736111</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.440078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>0.984903</td>\n",
       "      <td>-1.316034</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "17064 -1.364769 -0.745073      -0.027403     -0.146669     -0.216807   \n",
       "18434 -1.217915  0.708967      -0.416178     -0.146669     -0.216807   \n",
       "3294   0.911476  1.397806      -0.416178      0.451354     -0.216807   \n",
       "31317  1.058330 -0.736111       1.138922     -0.146669     -0.216807   \n",
       "4770   0.984903 -1.316034       1.138922     -0.146669     -0.216807   \n",
       "\n",
       "       hours.per.week  \n",
       "17064       -0.845065  \n",
       "18434        3.204805  \n",
       "3294         1.179870  \n",
       "31317       -0.440078  \n",
       "4770         1.179870  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_df = pd.DataFrame(scaler.transform(X_train_imp[numeric_features]),\n",
    "                           columns=numeric_features, index=X_train_imp.index)\n",
    "scaled_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note the same Golden Rule issue we talked about before.\n",
    "  - We fit the transformer on the training data, and then transform both data sets.\n",
    "  - We need to use a Pipeline for cross-validation because the transformation of each row depends on the other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_df = pd.DataFrame(scaler.transform(X_test_imp[numeric_features]),\n",
    "                           columns=numeric_features, index=X_test_imp.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that it did what we expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               3.634832e-16\n",
       "fnlwgt           -4.961863e-17\n",
       "education.num     1.371028e-15\n",
       "capital.gain     -3.863724e-16\n",
       "capital.loss      7.671122e-16\n",
       "hours.per.week    9.381657e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are basically all zero ($10^{-16}$ is zero to numerical precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               1.000019\n",
       "fnlwgt            1.000019\n",
       "education.num     1.000019\n",
       "capital.gain      1.000019\n",
       "capital.loss      1.000019\n",
       "hours.per.week    1.000019\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_df.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for test we get something different - that is OK!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              -0.001850\n",
       "fnlwgt            0.026132\n",
       "education.num     0.019814\n",
       "capital.gain      0.001331\n",
       "capital.loss     -0.004034\n",
       "hours.per.week    0.001708\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               1.007872\n",
       "fnlwgt            1.025728\n",
       "education.num     1.000891\n",
       "capital.gain      1.034391\n",
       "capital.loss      0.984757\n",
       "hours.per.week    1.000546\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_df.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-run our experiments now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.111493\n",
       "score_time     0.011850\n",
       "test_score     0.799217\n",
       "train_score    0.799505\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "pd.DataFrame(cross_validate(lr, X_train_imp[numeric_features], y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. With scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaling', StandardScaler()),\n",
    "                 ('lr', LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.056782\n",
       "score_time     0.011920\n",
       "test_score     0.814727\n",
       "train_score    0.815024\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(pipe, X_train_imp[numeric_features], y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we actually do a little better! Cool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. After messing with the data by rescaling some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.054141\n",
       "score_time     0.012030\n",
       "test_score     0.760519\n",
       "train_score    0.760519\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "pd.DataFrame(cross_validate(lr, X_train_mod[numeric_features], y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the same bad results we saw earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. After messing with the data, but using feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaling', StandardScaler()),\n",
    "                 ('lr', LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.057424\n",
       "score_time     0.012416\n",
       "test_score     0.814727\n",
       "train_score    0.815024\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(pipe, X_train_mod[numeric_features], y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAM! The scaling always sets the variance to 1, so the fact that we scaled up/down by 1000 is irrelevant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can redo the same experiments but with min/max scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaling', MinMaxScaler()),\n",
    "                 ('lr', LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.077138\n",
       "score_time     0.011946\n",
       "test_score     0.810427\n",
       "train_score    0.810888\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(pipe, X_train_imp[numeric_features], y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we get similar results. \n",
    "- We can also check that it does what it's supposed to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()\n",
    "minmax.fit(X_train_imp[numeric_features])\n",
    "normalized_train_df = minmax.transform(X_train_imp[numeric_features])\n",
    "normalized_test_df = minmax.transform(X_test_imp[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train_df.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train_df.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again for test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.00109735,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_test_df.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.08768803, 1.        , 1.        , 0.84550046,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_test_df.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the targets?\n",
    "\n",
    "- We'll discuss this when we get to numeric targets (regression) in a couple weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break (5 min)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together with `ColumnTransformer` (20 min)\n",
    "\n",
    "- Ok, so this is all great, but now we have ourselves a BIG MESS.\n",
    "- We have a Pipeline for the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cat = Pipeline([('imputation', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "                     ('lr', LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a pipeline for the numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_num = Pipeline([('scaler', StandardScaler()), # there were no missing values here\n",
    "                     ('lr', LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But we need to join together the scaled numeric features with the imputed/OHE'd categorical features BEFORE passing the whole dataframe into the classifier!\n",
    "- We can do this awkwardly without a Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "ohe     = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "scaler  = StandardScaler()\n",
    "lr      = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we process the categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>marital.status_Divorced</th>\n",
       "      <th>marital.status_Married-AF-spouse</th>\n",
       "      <th>...</th>\n",
       "      <th>native.country_Portugal</th>\n",
       "      <th>native.country_Puerto-Rico</th>\n",
       "      <th>native.country_Scotland</th>\n",
       "      <th>native.country_South</th>\n",
       "      <th>native.country_Taiwan</th>\n",
       "      <th>native.country_Thailand</th>\n",
       "      <th>native.country_Trinadad&amp;Tobago</th>\n",
       "      <th>native.country_United-States</th>\n",
       "      <th>native.country_Vietnam</th>\n",
       "      <th>native.country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
       "17064                    0.0                  0.0                     0.0   \n",
       "18434                    0.0                  0.0                     0.0   \n",
       "3294                     0.0                  0.0                     0.0   \n",
       "31317                    0.0                  0.0                     0.0   \n",
       "4770                     0.0                  0.0                     0.0   \n",
       "\n",
       "       workclass_Private  workclass_Self-emp-inc  workclass_Self-emp-not-inc  \\\n",
       "17064                1.0                     0.0                         0.0   \n",
       "18434                1.0                     0.0                         0.0   \n",
       "3294                 1.0                     0.0                         0.0   \n",
       "31317                1.0                     0.0                         0.0   \n",
       "4770                 0.0                     1.0                         0.0   \n",
       "\n",
       "       workclass_State-gov  workclass_Without-pay  marital.status_Divorced  \\\n",
       "17064                  0.0                    0.0                      0.0   \n",
       "18434                  0.0                    0.0                      0.0   \n",
       "3294                   0.0                    0.0                      0.0   \n",
       "31317                  0.0                    0.0                      0.0   \n",
       "4770                   0.0                    0.0                      0.0   \n",
       "\n",
       "       marital.status_Married-AF-spouse  ...  native.country_Portugal  \\\n",
       "17064                               0.0  ...                      0.0   \n",
       "18434                               0.0  ...                      0.0   \n",
       "3294                                0.0  ...                      0.0   \n",
       "31317                               0.0  ...                      0.0   \n",
       "4770                                0.0  ...                      0.0   \n",
       "\n",
       "       native.country_Puerto-Rico  native.country_Scotland  \\\n",
       "17064                         0.0                      0.0   \n",
       "18434                         0.0                      0.0   \n",
       "3294                          0.0                      0.0   \n",
       "31317                         0.0                      0.0   \n",
       "4770                          0.0                      0.0   \n",
       "\n",
       "       native.country_South  native.country_Taiwan  native.country_Thailand  \\\n",
       "17064                   0.0                    0.0                      0.0   \n",
       "18434                   0.0                    0.0                      0.0   \n",
       "3294                    0.0                    0.0                      0.0   \n",
       "31317                   0.0                    0.0                      0.0   \n",
       "4770                    0.0                    0.0                      0.0   \n",
       "\n",
       "       native.country_Trinadad&Tobago  native.country_United-States  \\\n",
       "17064                             0.0                           1.0   \n",
       "18434                             0.0                           1.0   \n",
       "3294                              0.0                           1.0   \n",
       "31317                             0.0                           1.0   \n",
       "4770                              0.0                           1.0   \n",
       "\n",
       "       native.country_Vietnam  native.country_Yugoslavia  \n",
       "17064                     0.0                        0.0  \n",
       "18434                     0.0                        0.0  \n",
       "3294                      0.0                        0.0  \n",
       "31317                     0.0                        0.0  \n",
       "4770                      0.0                        0.0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train = X_train_nan[categorical_features]\n",
    "cat_train_imp = imputer.fit_transform(cat_train)\n",
    "cat_train_imp_ohe = ohe.fit_transform(cat_train_imp)\n",
    "cat_train_imp_ohe_df = pd.DataFrame(data=cat_train_imp_ohe, columns=ohe.get_feature_names(categorical_features), index=X_train_nan.index)\n",
    "cat_train_imp_ohe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we process the numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>-1.364769</td>\n",
       "      <td>-0.745073</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.845065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>-1.217915</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>3.204805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>0.911476</td>\n",
       "      <td>1.397806</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>0.451354</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>1.058330</td>\n",
       "      <td>-0.736111</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.440078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>0.984903</td>\n",
       "      <td>-1.316034</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>0.691194</td>\n",
       "      <td>-1.129174</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.774883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>-0.263361</td>\n",
       "      <td>1.436102</td>\n",
       "      <td>-1.582503</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.197086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28030</th>\n",
       "      <td>-0.924206</td>\n",
       "      <td>1.755487</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.126904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>-0.777351</td>\n",
       "      <td>-0.320086</td>\n",
       "      <td>-2.748829</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.035091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>0.103776</td>\n",
       "      <td>-0.361296</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.612888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "17064 -1.364769 -0.745073      -0.027403     -0.146669     -0.216807   \n",
       "18434 -1.217915  0.708967      -0.416178     -0.146669     -0.216807   \n",
       "3294   0.911476  1.397806      -0.416178      0.451354     -0.216807   \n",
       "31317  1.058330 -0.736111       1.138922     -0.146669     -0.216807   \n",
       "4770   0.984903 -1.316034       1.138922     -0.146669     -0.216807   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "28636  0.691194 -1.129174      -0.416178     -0.146669     -0.216807   \n",
       "17730 -0.263361  1.436102      -1.582503     -0.146669     -0.216807   \n",
       "28030 -0.924206  1.755487      -0.027403     -0.146669     -0.216807   \n",
       "15725 -0.777351 -0.320086      -2.748829     -0.146669     -0.216807   \n",
       "19966  0.103776 -0.361296      -0.416178     -0.146669     -0.216807   \n",
       "\n",
       "       hours.per.week  \n",
       "17064       -0.845065  \n",
       "18434        3.204805  \n",
       "3294         1.179870  \n",
       "31317       -0.440078  \n",
       "4770         1.179870  \n",
       "...               ...  \n",
       "28636        0.774883  \n",
       "17730       -0.197086  \n",
       "28030        0.126904  \n",
       "15725       -0.035091  \n",
       "19966        0.612888  \n",
       "\n",
       "[26048 rows x 6 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = X_train_nan[numeric_features]\n",
    "num_train_scaler = scaler.fit_transform(num_train)\n",
    "num_train_scaler_df = pd.DataFrame(data=num_train_scaler, columns=numeric_features, index=X_train_nan.index)\n",
    "num_train_scaler_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we smush them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native.country_Portugal</th>\n",
       "      <th>native.country_Puerto-Rico</th>\n",
       "      <th>native.country_Scotland</th>\n",
       "      <th>native.country_South</th>\n",
       "      <th>native.country_Taiwan</th>\n",
       "      <th>native.country_Thailand</th>\n",
       "      <th>native.country_Trinadad&amp;Tobago</th>\n",
       "      <th>native.country_United-States</th>\n",
       "      <th>native.country_Vietnam</th>\n",
       "      <th>native.country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>-1.364769</td>\n",
       "      <td>-0.745073</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.845065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>-1.217915</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>3.204805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>0.911476</td>\n",
       "      <td>1.397806</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>0.451354</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>1.058330</td>\n",
       "      <td>-0.736111</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.440078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>0.984903</td>\n",
       "      <td>-1.316034</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>0.691194</td>\n",
       "      <td>-1.129174</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.774883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>-0.263361</td>\n",
       "      <td>1.436102</td>\n",
       "      <td>-1.582503</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.197086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28030</th>\n",
       "      <td>-0.924206</td>\n",
       "      <td>1.755487</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.126904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>-0.777351</td>\n",
       "      <td>-0.320086</td>\n",
       "      <td>-2.748829</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.035091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>0.103776</td>\n",
       "      <td>-0.361296</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.612888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "17064 -1.364769 -0.745073      -0.027403     -0.146669     -0.216807   \n",
       "18434 -1.217915  0.708967      -0.416178     -0.146669     -0.216807   \n",
       "3294   0.911476  1.397806      -0.416178      0.451354     -0.216807   \n",
       "31317  1.058330 -0.736111       1.138922     -0.146669     -0.216807   \n",
       "4770   0.984903 -1.316034       1.138922     -0.146669     -0.216807   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "28636  0.691194 -1.129174      -0.416178     -0.146669     -0.216807   \n",
       "17730 -0.263361  1.436102      -1.582503     -0.146669     -0.216807   \n",
       "28030 -0.924206  1.755487      -0.027403     -0.146669     -0.216807   \n",
       "15725 -0.777351 -0.320086      -2.748829     -0.146669     -0.216807   \n",
       "19966  0.103776 -0.361296      -0.416178     -0.146669     -0.216807   \n",
       "\n",
       "       hours.per.week  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "17064       -0.845065                    0.0                  0.0   \n",
       "18434        3.204805                    0.0                  0.0   \n",
       "3294         1.179870                    0.0                  0.0   \n",
       "31317       -0.440078                    0.0                  0.0   \n",
       "4770         1.179870                    0.0                  0.0   \n",
       "...               ...                    ...                  ...   \n",
       "28636        0.774883                    0.0                  0.0   \n",
       "17730       -0.197086                    0.0                  0.0   \n",
       "28030        0.126904                    0.0                  0.0   \n",
       "15725       -0.035091                    0.0                  0.0   \n",
       "19966        0.612888                    0.0                  0.0   \n",
       "\n",
       "       workclass_Never-worked  workclass_Private  ...  \\\n",
       "17064                     0.0                1.0  ...   \n",
       "18434                     0.0                1.0  ...   \n",
       "3294                      0.0                1.0  ...   \n",
       "31317                     0.0                1.0  ...   \n",
       "4770                      0.0                0.0  ...   \n",
       "...                       ...                ...  ...   \n",
       "28636                     0.0                1.0  ...   \n",
       "17730                     0.0                1.0  ...   \n",
       "28030                     0.0                1.0  ...   \n",
       "15725                     0.0                1.0  ...   \n",
       "19966                     0.0                1.0  ...   \n",
       "\n",
       "       native.country_Portugal  native.country_Puerto-Rico  \\\n",
       "17064                      0.0                         0.0   \n",
       "18434                      0.0                         0.0   \n",
       "3294                       0.0                         0.0   \n",
       "31317                      0.0                         0.0   \n",
       "4770                       0.0                         0.0   \n",
       "...                        ...                         ...   \n",
       "28636                      0.0                         0.0   \n",
       "17730                      0.0                         0.0   \n",
       "28030                      0.0                         0.0   \n",
       "15725                      0.0                         0.0   \n",
       "19966                      0.0                         0.0   \n",
       "\n",
       "       native.country_Scotland  native.country_South  native.country_Taiwan  \\\n",
       "17064                      0.0                   0.0                    0.0   \n",
       "18434                      0.0                   0.0                    0.0   \n",
       "3294                       0.0                   0.0                    0.0   \n",
       "31317                      0.0                   0.0                    0.0   \n",
       "4770                       0.0                   0.0                    0.0   \n",
       "...                        ...                   ...                    ...   \n",
       "28636                      0.0                   0.0                    0.0   \n",
       "17730                      0.0                   0.0                    0.0   \n",
       "28030                      0.0                   0.0                    0.0   \n",
       "15725                      0.0                   0.0                    0.0   \n",
       "19966                      0.0                   0.0                    0.0   \n",
       "\n",
       "       native.country_Thailand  native.country_Trinadad&Tobago  \\\n",
       "17064                      0.0                             0.0   \n",
       "18434                      0.0                             0.0   \n",
       "3294                       0.0                             0.0   \n",
       "31317                      0.0                             0.0   \n",
       "4770                       0.0                             0.0   \n",
       "...                        ...                             ...   \n",
       "28636                      0.0                             0.0   \n",
       "17730                      0.0                             0.0   \n",
       "28030                      0.0                             0.0   \n",
       "15725                      0.0                             0.0   \n",
       "19966                      0.0                             0.0   \n",
       "\n",
       "       native.country_United-States  native.country_Vietnam  \\\n",
       "17064                           1.0                     0.0   \n",
       "18434                           1.0                     0.0   \n",
       "3294                            1.0                     0.0   \n",
       "31317                           1.0                     0.0   \n",
       "4770                            1.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "28636                           1.0                     0.0   \n",
       "17730                           1.0                     0.0   \n",
       "28030                           1.0                     0.0   \n",
       "15725                           0.0                     0.0   \n",
       "19966                           1.0                     0.0   \n",
       "\n",
       "       native.country_Yugoslavia  \n",
       "17064                        0.0  \n",
       "18434                        0.0  \n",
       "3294                         0.0  \n",
       "31317                        0.0  \n",
       "4770                         0.0  \n",
       "...                          ...  \n",
       "28636                        0.0  \n",
       "17730                        0.0  \n",
       "28030                        0.0  \n",
       "15725                        0.0  \n",
       "19966                        0.0  \n",
       "\n",
       "[26048 rows x 89 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_this_is_so_annoying = pd.concat((num_train_scaler_df, cat_train_imp_ohe_df), axis=1)\n",
    "X_train_this_is_so_annoying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8523495085995086"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_this_is_so_annoying, y_train)\n",
    "lr.score(X_train_this_is_so_annoying, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, time to do all that again for the test data!\n",
    "\n",
    "![](img/mike_not_gonna_happen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Right, so the above is horribly messy and also results in a Golden Rule violation if we do cross-validation.\n",
    "- Enter `ColumnTransformer` to save the day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/column-transformer.png\" width=800>\n",
    "\n",
    "Image adapted from [here](https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/#37)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A big advantage here is that we build all our transformations together into one object, and that way we're sure we do the same operations to all splits of the data. \n",
    "- Otherwise we might, for example, do the OHE on both train and test but forget to scale the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get to work! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('scale', StandardScaler(), numeric_features),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above:\n",
    "\n",
    "- The `ColumnTransformer` syntax is somewhat similar to `Pipeline` in that you pass in a list of tuples.\n",
    "- But here each tuple has 3 values instead of 2: (name, object, list of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native.country_Portugal</th>\n",
       "      <th>native.country_Puerto-Rico</th>\n",
       "      <th>native.country_Scotland</th>\n",
       "      <th>native.country_South</th>\n",
       "      <th>native.country_Taiwan</th>\n",
       "      <th>native.country_Thailand</th>\n",
       "      <th>native.country_Trinadad&amp;Tobago</th>\n",
       "      <th>native.country_United-States</th>\n",
       "      <th>native.country_Vietnam</th>\n",
       "      <th>native.country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>-1.364769</td>\n",
       "      <td>-0.745073</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.845065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>-1.217915</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>3.204805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>0.911476</td>\n",
       "      <td>1.397806</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>0.451354</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>1.058330</td>\n",
       "      <td>-0.736111</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.440078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>0.984903</td>\n",
       "      <td>-1.316034</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>0.691194</td>\n",
       "      <td>-1.129174</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.774883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>-0.263361</td>\n",
       "      <td>1.436102</td>\n",
       "      <td>-1.582503</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.197086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28030</th>\n",
       "      <td>-0.924206</td>\n",
       "      <td>1.755487</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.126904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>-0.777351</td>\n",
       "      <td>-0.320086</td>\n",
       "      <td>-2.748829</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.035091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>0.103776</td>\n",
       "      <td>-0.361296</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>0.612888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "17064 -1.364769 -0.745073      -0.027403     -0.146669     -0.216807   \n",
       "18434 -1.217915  0.708967      -0.416178     -0.146669     -0.216807   \n",
       "3294   0.911476  1.397806      -0.416178      0.451354     -0.216807   \n",
       "31317  1.058330 -0.736111       1.138922     -0.146669     -0.216807   \n",
       "4770   0.984903 -1.316034       1.138922     -0.146669     -0.216807   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "28636  0.691194 -1.129174      -0.416178     -0.146669     -0.216807   \n",
       "17730 -0.263361  1.436102      -1.582503     -0.146669     -0.216807   \n",
       "28030 -0.924206  1.755487      -0.027403     -0.146669     -0.216807   \n",
       "15725 -0.777351 -0.320086      -2.748829     -0.146669     -0.216807   \n",
       "19966  0.103776 -0.361296      -0.416178     -0.146669     -0.216807   \n",
       "\n",
       "       hours.per.week  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "17064       -0.845065                    0.0                  0.0   \n",
       "18434        3.204805                    0.0                  0.0   \n",
       "3294         1.179870                    0.0                  0.0   \n",
       "31317       -0.440078                    0.0                  0.0   \n",
       "4770         1.179870                    0.0                  0.0   \n",
       "...               ...                    ...                  ...   \n",
       "28636        0.774883                    0.0                  0.0   \n",
       "17730       -0.197086                    0.0                  0.0   \n",
       "28030        0.126904                    0.0                  0.0   \n",
       "15725       -0.035091                    0.0                  0.0   \n",
       "19966        0.612888                    0.0                  0.0   \n",
       "\n",
       "       workclass_Never-worked  workclass_Private  ...  \\\n",
       "17064                     0.0                1.0  ...   \n",
       "18434                     0.0                1.0  ...   \n",
       "3294                      0.0                1.0  ...   \n",
       "31317                     0.0                1.0  ...   \n",
       "4770                      0.0                0.0  ...   \n",
       "...                       ...                ...  ...   \n",
       "28636                     0.0                1.0  ...   \n",
       "17730                     0.0                1.0  ...   \n",
       "28030                     0.0                1.0  ...   \n",
       "15725                     0.0                1.0  ...   \n",
       "19966                     0.0                1.0  ...   \n",
       "\n",
       "       native.country_Portugal  native.country_Puerto-Rico  \\\n",
       "17064                      0.0                         0.0   \n",
       "18434                      0.0                         0.0   \n",
       "3294                       0.0                         0.0   \n",
       "31317                      0.0                         0.0   \n",
       "4770                       0.0                         0.0   \n",
       "...                        ...                         ...   \n",
       "28636                      0.0                         0.0   \n",
       "17730                      0.0                         0.0   \n",
       "28030                      0.0                         0.0   \n",
       "15725                      0.0                         0.0   \n",
       "19966                      0.0                         0.0   \n",
       "\n",
       "       native.country_Scotland  native.country_South  native.country_Taiwan  \\\n",
       "17064                      0.0                   0.0                    0.0   \n",
       "18434                      0.0                   0.0                    0.0   \n",
       "3294                       0.0                   0.0                    0.0   \n",
       "31317                      0.0                   0.0                    0.0   \n",
       "4770                       0.0                   0.0                    0.0   \n",
       "...                        ...                   ...                    ...   \n",
       "28636                      0.0                   0.0                    0.0   \n",
       "17730                      0.0                   0.0                    0.0   \n",
       "28030                      0.0                   0.0                    0.0   \n",
       "15725                      0.0                   0.0                    0.0   \n",
       "19966                      0.0                   0.0                    0.0   \n",
       "\n",
       "       native.country_Thailand  native.country_Trinadad&Tobago  \\\n",
       "17064                      0.0                             0.0   \n",
       "18434                      0.0                             0.0   \n",
       "3294                       0.0                             0.0   \n",
       "31317                      0.0                             0.0   \n",
       "4770                       0.0                             0.0   \n",
       "...                        ...                             ...   \n",
       "28636                      0.0                             0.0   \n",
       "17730                      0.0                             0.0   \n",
       "28030                      0.0                             0.0   \n",
       "15725                      0.0                             0.0   \n",
       "19966                      0.0                             0.0   \n",
       "\n",
       "       native.country_United-States  native.country_Vietnam  \\\n",
       "17064                           1.0                     0.0   \n",
       "18434                           1.0                     0.0   \n",
       "3294                            1.0                     0.0   \n",
       "31317                           1.0                     0.0   \n",
       "4770                            1.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "28636                           1.0                     0.0   \n",
       "17730                           1.0                     0.0   \n",
       "28030                           1.0                     0.0   \n",
       "15725                           0.0                     0.0   \n",
       "19966                           1.0                     0.0   \n",
       "\n",
       "       native.country_Yugoslavia  \n",
       "17064                        0.0  \n",
       "18434                        0.0  \n",
       "3294                         0.0  \n",
       "31317                        0.0  \n",
       "4770                         0.0  \n",
       "...                          ...  \n",
       "28636                        0.0  \n",
       "17730                        0.0  \n",
       "28030                        0.0  \n",
       "15725                        0.0  \n",
       "19966                        0.0  \n",
       "\n",
       "[26048 rows x 89 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preproc = preprocessor.fit_transform(X_train_imp)\n",
    "new_columns = numeric_features + list(preprocessor.named_transformers_['ohe'].get_feature_names(categorical_features))\n",
    "pd.DataFrame(data=X_train_preproc, columns=new_columns, index=X_train_imp.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BAM! Scaling and OHE applied at the same time!\n",
    "- When we `fit` the `ColumnTransformer`, it fits _all_ the transformers. And likewise for `transform`.\n",
    "- Warning: by default `ColumnTransformer` throws away any columns not accounted for in its steps.\n",
    "- Setting `remainder='passthrough'` keeps the rest of the columns in tact as in the image above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's put everything together in a pipeline: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt 1: one pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use the preprocessor as a step in the pipeline!\n",
    "- This step treats numeric features and categorical features differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('preproc', preprocessor), # <-- this is the ColumnTransformer!\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/miniconda3/envs/cpsc330env/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mall_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-a2e0e5c89735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/cpsc330env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/opt/miniconda3/envs/cpsc330env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cpsc330env/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cpsc330env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cpsc330env/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cpsc330env/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_remainder\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mremaining_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cpsc330env/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mall_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             raise ValueError(\"Specifying the columns using strings is only \"\n\u001b[0m\u001b[1;32m    428\u001b[0m                              \"supported for pandas DataFrames\")\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ugh. What happened?\n",
    "- The problem is that `SimpleImputer.transform` outputs a numpy array, not a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Private', 'Never-married', 'Adm-clerical', ...,\n",
       "        'Asian-Pac-Islander', 'Female', 'United-States'],\n",
       "       ['Private', 'Never-married', 'Other-service', ..., 'Black',\n",
       "        'Male', 'United-States'],\n",
       "       ['Private', 'Married-civ-spouse', 'Exec-managerial', ..., 'White',\n",
       "        'Male', 'United-States'],\n",
       "       ...,\n",
       "       ['Private', 'Married-civ-spouse', 'Adm-clerical', ..., 'White',\n",
       "        'Female', 'United-States'],\n",
       "       ['Private', 'Never-married', 'Craft-repair', ..., 'White', 'Male',\n",
       "        'Columbia'],\n",
       "       ['Private', 'Divorced', 'Handlers-cleaners', ..., 'White',\n",
       "        'Female', 'United-States']], dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.transform(X_train_nan[categorical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been putting it into a dataframe manually so that it looks nice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>Private</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>Private</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>Private</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28030</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>Private</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          workclass      marital.status         occupation   relationship  \\\n",
       "17064       Private       Never-married       Adm-clerical      Own-child   \n",
       "18434       Private       Never-married      Other-service      Own-child   \n",
       "3294        Private  Married-civ-spouse    Exec-managerial        Husband   \n",
       "31317       Private  Married-civ-spouse      Other-service        Husband   \n",
       "4770   Self-emp-inc  Married-civ-spouse              Sales        Husband   \n",
       "...             ...                 ...                ...            ...   \n",
       "28636       Private  Married-civ-spouse  Machine-op-inspct           Wife   \n",
       "17730       Private       Never-married      Other-service      Unmarried   \n",
       "28030       Private  Married-civ-spouse       Adm-clerical           Wife   \n",
       "15725       Private       Never-married       Craft-repair  Not-in-family   \n",
       "19966       Private            Divorced  Handlers-cleaners  Not-in-family   \n",
       "\n",
       "                     race     sex native.country  \n",
       "17064  Asian-Pac-Islander  Female  United-States  \n",
       "18434               Black    Male  United-States  \n",
       "3294                White    Male  United-States  \n",
       "31317               White    Male  United-States  \n",
       "4770                White    Male  United-States  \n",
       "...                   ...     ...            ...  \n",
       "28636               White  Female  United-States  \n",
       "17730               Black  Female  United-States  \n",
       "28030               White  Female  United-States  \n",
       "15725               White    Male       Columbia  \n",
       "19966               White  Female  United-States  \n",
       "\n",
       "[26048 rows x 7 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=imputer.transform(X_train_nan[categorical_features]), columns=categorical_features, index=X_train_nan.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, when we made the `ColumnTransformer` we referred to columns _by name_ rather than by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('scale', StandardScaler(), numeric_features),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'fnlwgt',\n",
       " 'education.num',\n",
       " 'capital.gain',\n",
       " 'capital.loss',\n",
       " 'hours.per.week']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'marital.status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native.country']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can't use these names if it's getting a numpy array where the columns aren't named."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt 2: separate pipeline for each feature type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a pipeline for the categorical features (preprocessing only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cat = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need a pipeline for the numerical features because there's only one step, scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put these together to make a `ColumnTransformer` for all the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', pipe_cat, categorical_features),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a minute to digest this... what does it do.\n",
    "- When ready, let's combine this with the classifier in _another pipeline_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "     'classifier', LogisticRegression(max_iter=1000)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we fit the preprocessor, it fits _all_ the transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the new names of the columns that were generated by the one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.named_transformers_['ohe'].get_feature_names(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining this with the numeric feature names gives us all the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = numeric_features + list(preprocessor.named_transformers_['ohe']\n",
    "                                     .get_feature_names(categorical_features))\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperopt code from lecture 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              \"n_estimators\"     : [10,100],\n",
    "              \"max_depth\"        : [3, None],\n",
    "              \"max_features\"     : [3, None]\n",
    "             }\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many combinations in total? \n",
    "- $2\\times 2\\times 2=8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.prod(list(map(len, param_grid.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=321)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_transformed, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lol... these are the default values.\n",
    "- I guess they picked good defaults!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'param_max_depth', 'param_max_features', 'param_n_estimators', 'mean_fit_time', 'rank_test_score']].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that the grid search object acts like a scikit-learn model.\n",
    "- It was actually refit on the _whole_ training set, as discussed earlier in the course!\n",
    "- I believe it is the same as `grid_search.best_estimator_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "using columntransformer to combine mutliple OHEs where you only specify the categories in some\n",
    "\n",
    "note: actually you can use the `categories=[cats_1, cats_2]` -> too bad a dict is not allowed here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "look at old hyperopt lecture, get the hyperopt code that goes multiple levels deep with `__` because we now have many transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different classifiers (10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's use cross-validation with our training set.\n",
    "- This is implemented in `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr, X_train_scale_ohe, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0 - np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also the slightly more sophisticated `cross_validate`, which gives us some extra information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(lr, X_train_scale_ohe, y_train, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores).drop(columns=['score_time'])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try some different classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "models = {'decision tree'      : DecisionTreeClassifier(),\n",
    "          'logistic regression': LogisticRegression(max_iter=300),\n",
    "          'RBF SVM'            : SVC(max_iter=1500), \n",
    "          'random forest'      : RandomForestClassifier(), \n",
    "         }\n",
    "avg_scores = dict()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    scores = cross_validate(model, X_train_scale_ohe, y_train, cv=5, return_train_score=True)\n",
    "    avg_scores[model_name] = pd.DataFrame(scores).drop(columns=['score_time']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(avg_scores).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss these results:\n",
    "\n",
    "- Which methods are overfitting?\n",
    "- Which methods are underfitting?\n",
    "- Which methods are fast/slow?\n",
    "- What is the best method so far?\n",
    "- What hyperparameters should we tune?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'decision tree'      : DecisionTreeClassifier(),\n",
    "          'logistic regression orig': LogisticRegression(max_iter=300),\n",
    "          'logistic regression': LogisticRegression(max_iter=300, C=100),\n",
    "          'random forest orig'      : RandomForestClassifier(), \n",
    "          'random forest simpler'   : RandomForestClassifier(n_estimators=10)\n",
    "         }\n",
    "avg_scores = dict()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    scores = cross_validate(model, X_train_scale_ohe, y_train, cv=5, return_train_score=True)\n",
    "    avg_scores[model_name] = pd.DataFrame(scores).drop(columns=['score_time']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(avg_scores).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary (5 min)\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
