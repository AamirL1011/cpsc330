{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CPSC 330 Lecture 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Lecture plan\n",
    "\n",
    "- 👋\n",
    "- **Turn on recording**\n",
    "- Announcements (5 min)\n",
    "- Evaluation metrics True/False (10 min)\n",
    "- Introducing some other classifiers (20 min)\n",
    "- Break (5 mins)\n",
    "- Ensembles: averaging (20 min)\n",
    "- Ensembles: stacking (20 min)\n",
    "- Summary\n",
    "\n",
    "Piazza:\n",
    "\n",
    "- Ensembles True/False questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements\n",
    "\n",
    "- hw schedule for the rest of the course posted at https://github.com/UBC-CS/cpsc330#homework-schedule\n",
    "- hw4 posted, due Monday 11:59pm\n",
    "- Evaluation metrics true/false: https://piazza.com/class/kb2e6nwu3uj23?cid=283\n",
    "- Midterm format poll: https://piazza.com/class/kb2e6nwu3uj23?cid=281"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Name a few popular tree-based classifier.\n",
    "- Name a few key hyperparameters of random forest classifiers.\n",
    "- Weigh the pros and cons of using a classifier from outside scikit-learn.\n",
    "- Employ ensemble classifier approaches, in particular model averaging and stacking\n",
    "- Compare averaging vs. stacking\n",
    "- Interpret the coefficients of the meta-classifier in the case of stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def display_tree(feature_names, tree):\n",
    "    \"\"\" For binary classification only \"\"\"\n",
    "    dot = export_graphviz(tree, out_file=None, feature_names=feature_names, class_names=tree.classes_.astype(str), impurity=False)\n",
    "    # adapted from https://stackoverflow.com/questions/44821349/python-graphviz-remove-legend-on-nodes-of-decisiontreeclassifier\n",
    "    dot = re.sub('(\\\\\\\\nsamples = [0-9]+)(\\\\\\\\nvalue = \\[[0-9]+, [0-9]+\\])(\\\\\\\\nclass = [A-Za-z0-9]+)', '', dot)\n",
    "    dot = re.sub(     '(samples = [0-9]+)(\\\\\\\\nvalue = \\[[0-9]+, [0-9]+\\])\\\\\\\\n', '', dot)\n",
    "    return graphviz.Source(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing some other classifiers (20 min)\n",
    "\n",
    "- SVM?\n",
    "- Random forest\n",
    "- XGB, Catboost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cc_df = pd.read_csv('data/creditcard.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today I will use a smaller data set for speed of the demos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = cc_df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(cc_df, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21360, 31)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['Class'])\n",
    "y_train = df_train['Class']\n",
    "\n",
    "X_test = df_test.drop(columns=['Class'])\n",
    "y_test = df_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = 'average_precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.152092\n",
       "score_time     0.004988\n",
       "test_score     0.690253\n",
       "train_score    0.773068\n",
       "dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results = pd.DataFrame(cross_validate(pipe_lr, X_train, y_train, scoring=score_method, return_train_score=True)).mean()\n",
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(class_weight='balanced') # scaling not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.161050\n",
       "score_time     0.002695\n",
       "test_score     0.510938\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results = pd.DataFrame(cross_validate(dt, X_train, y_train, scoring=score_method, return_train_score=True)).mean()\n",
    "dt_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about some other classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is basically the average of a bunch of random decision trees. \n",
    "- We'll talk about averaging later today!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', random_state=999) # scaling not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       2.023708\n",
       "score_time     0.024301\n",
       "test_score     0.760333\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results = pd.DataFrame(cross_validate(rf, X_train, y_train, scoring=score_method, return_train_score=True)).mean()\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets a better score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>2.023708</td>\n",
       "      <td>0.024301</td>\n",
       "      <td>0.760333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.152092</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.690253</td>\n",
       "      <td>0.773068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.161050</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.510938</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fit_time  score_time  test_score  train_score\n",
       "random forest        2.023708    0.024301    0.760333     1.000000\n",
       "logistic regression  0.152092    0.004988    0.690253     0.773068\n",
       "decision tree        0.161050    0.002695    0.510938     1.000000"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame([lr_results, dt_results, rf_results], index=[\"logistic regression\", \"decision tree\", \"random forest\"])\n",
    "summary.sort_values(by=[\"test_score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are these random forests you speak of?\n",
    "\n",
    "- They are a collection of decision trees.\n",
    "- Each tree \"votes\" on the prediction, majority rules (more on this later).\n",
    "- Each tree (and split) is limited in the number of features it can look at.\n",
    "- Each tree is training on a slightly different version of the dataset. \n",
    "\n",
    "We can actually look at the sub-trees in a trained random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tree 1\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"381pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 381.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 377,-184 377,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"241,-180 131,-180 131,-144 241,-144 241,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V17 &lt;= &#45;2.532.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"179,-108 69,-108 69,-72 179,-72 179,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V14 &lt;= &#45;3.358.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M170.3548,-143.8314C163.1409,-135.454 154.443,-125.3531 146.5395,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"149.0333,-113.7071 139.8559,-108.4133 143.7289,-118.2748 149.0333,-113.7071\"/>\n",
       "<text text-anchor=\"middle\" x=\"137.9954\" y=\"-129.6439\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"300.5,-108 197.5,-108 197.5,-72 300.5,-72 300.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V3 &lt;= &#45;4.964.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M201.8976,-143.8314C209.2278,-135.454 218.066,-125.3531 226.0969,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.9373,-118.2438 232.8884,-108.4133 223.6693,-113.6343 228.9373,-118.2438\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5514\" y=\"-129.6579\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"76,-36 0,-36 0,0 76,0 76,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"38\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M102.2986,-71.8314C91.8079,-63.0485 79.0545,-52.3712 67.6806,-42.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.6089,-39.8986 59.6945,-36.1628 65.1153,-45.2659 69.6089,-39.8986\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"170,-36 94,-36 94,0 170,0 170,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M126.0187,-71.8314C126.8743,-64.131 127.8917,-54.9743 128.8426,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"132.3283,-46.7386 129.9541,-36.4133 125.3711,-45.9656 132.3283,-46.7386\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"279,-36 203,-36 203,0 279,0 279,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"241\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M246.9813,-71.8314C246.1257,-64.131 245.1083,-54.9743 244.1574,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"247.6289,-45.9656 243.0459,-36.4133 240.6717,-46.7386 247.6289,-45.9656\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"373,-36 297,-36 297,0 373,0 373,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"335\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M270.7014,-71.8314C281.1921,-63.0485 293.9455,-52.3712 305.3194,-42.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.8847,-45.2659 313.3055,-36.1628 303.3911,-39.8986 307.8847,-45.2659\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa732741b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tree 2\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"379pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 379.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 375,-184 375,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"240,-180 130,-180 130,-144 240,-144 240,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"185\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V12 &lt;= &#45;4.158.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"176.5,-108 73.5,-108 73.5,-72 176.5,-72 176.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"125\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V6 &lt;= &#45;2.999.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M169.8595,-143.8314C162.8783,-135.454 154.4609,-125.3531 146.8124,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"149.4351,-113.8548 140.3444,-108.4133 144.0575,-118.3362 149.4351,-113.8548\"/>\n",
       "<text text-anchor=\"middle\" x=\"138.081\" y=\"-129.6106\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"297.5,-108 194.5,-108 194.5,-72 297.5,-72 297.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V5 &lt;= &#45;3.962.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M200.3929,-143.8314C207.4904,-135.454 216.048,-125.3531 223.824,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"226.6061,-118.3056 230.3999,-108.4133 221.2652,-113.7807 226.6061,-118.3056\"/>\n",
       "<text text-anchor=\"middle\" x=\"232.4605\" y=\"-129.6282\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"76,-36 0,-36 0,0 76,0 76,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"38\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103.0462,-71.8314C92.3305,-62.9632 79.2811,-52.1637 67.691,-42.5718\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.8822,-39.8422 59.9467,-36.1628 65.4192,-45.2349 69.8822,-39.8422\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"170,-36 94,-36 94,0 170,0 170,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M126.7664,-71.8314C127.515,-64.131 128.4053,-54.9743 129.2373,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"132.7256,-46.7051 130.2098,-36.4133 125.7585,-46.0276 132.7256,-46.7051\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"277,-36 201,-36 201,0 277,0 277,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"239\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M244.2336,-71.8314C243.485,-64.131 242.5947,-54.9743 241.7627,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"245.2415,-46.0276 240.7902,-36.4133 238.2744,-46.7051 245.2415,-46.0276\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"371,-36 295,-36 295,0 371,0 371,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"333\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M267.9538,-71.8314C278.6695,-62.9632 291.7189,-52.1637 303.309,-42.5718\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.5808,-45.2349 311.0533,-36.1628 301.1178,-39.8422 305.5808,-45.2349\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa732741eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tree 3\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"382pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 382.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 378,-184 378,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"238.5,-180 135.5,-180 135.5,-144 238.5,-144 238.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V9 &lt;= &#45;3.512.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"176.5,-108 71.5,-108 71.5,-72 176.5,-72 176.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V20 &lt;= 3.008.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M171.1024,-143.8314C163.7722,-135.454 154.934,-125.3531 146.9031,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"149.3307,-113.6343 140.1116,-108.4133 144.0627,-118.2438 149.3307,-113.6343\"/>\n",
       "<text text-anchor=\"middle\" x=\"138.4486\" y=\"-129.6579\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"305,-108 195,-108 195,-72 305,-72 305,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"250\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V14 &lt;= &#45;4.601.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M202.8976,-143.8314C210.2278,-135.454 219.066,-125.3531 227.0969,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"229.9373,-118.2438 233.8884,-108.4133 224.6693,-113.6343 229.9373,-118.2438\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.5514\" y=\"-129.6579\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"76,-36 0,-36 0,0 76,0 76,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"38\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M102.2986,-71.8314C91.8079,-63.0485 79.0545,-52.3712 67.6806,-42.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.6089,-39.8986 59.6945,-36.1628 65.1153,-45.2659 69.6089,-39.8986\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"170,-36 94,-36 94,0 170,0 170,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M126.0187,-71.8314C126.8743,-64.131 127.8917,-54.9743 128.8426,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"132.3283,-46.7386 129.9541,-36.4133 125.3711,-45.9656 132.3283,-46.7386\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"280,-36 204,-36 204,0 280,0 280,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M247.9813,-71.8314C247.1257,-64.131 246.1083,-54.9743 245.1574,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.6289,-45.9656 244.0459,-36.4133 241.6717,-46.7386 248.6289,-45.9656\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"374,-36 298,-36 298,0 374,0 374,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M271.7014,-71.8314C282.1921,-63.0485 294.9455,-52.3712 306.3194,-42.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"308.8847,-45.2659 314.3055,-36.1628 304.3911,-39.8986 308.8847,-45.2659\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa732741f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_demo = RandomForestClassifier(max_depth=2, n_estimators=3)\n",
    "rf_demo.fit(X_train, y_train)\n",
    "for i, tree in enumerate(rf_demo.estimators_):\n",
    "    print(\"\\n\\nTree\", i+1)\n",
    "    display(display_tree(X_train.columns, tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that they look at different features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notable hyperparameters:\n",
    "\n",
    "- `n_estimators`: number of decision trees (higher = more complexity)\n",
    "- `max_depth`: max depth of each decision tree (higher = more complexity)\n",
    "- `max_features`: the number of features you get to look at each split (higher = more complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also try some other tree-based classifiers from outside sklearn.\n",
    "- There are more \"fancy\" are are **extremely popular**.  \n",
    "- Over time, people created \"sklearn-friendly\" wrappers so that these classifiers are compatible with all that we know & love.\n",
    "  - As long as they implement `fit` and `predict` and `predict_proba` and `score` we can plug them right in.\n",
    "  - Important to note that all of these **do** implement `predict_proba` so we can use something like ROC AUC.\n",
    "  - The probability scores come from the variation in the votes across trees, and other fancier sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`XGBClassifier` doesn't have an easy implementation of `class_weight='balanced'` AFAIK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    463.347826\n",
       "1      1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = y_train.value_counts()\n",
    "vc = vc/vc.iloc[1]\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'logistic regression' : pipe_lr,\n",
    "    'decision tree' : dt,\n",
    "    'random forest' : rf,\n",
    "    'XGBoost' : XGBClassifier(scale_pos_weight=500, random_state=999), \n",
    "    'LightGBM' : LGBMClassifier(class_weight='balanced', random_state=999),\n",
    "    'CatBoost' : CatBoostClassifier(auto_class_weights='Balanced', verbose=0, random_state=999)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression\n",
      "decision tree\n",
      "random forest\n",
      "XGBoost\n",
      "LightGBM\n",
      "CatBoost\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "for name, classifier in classifiers.items():\n",
    "    print(name)\n",
    "    results[name] = pd.DataFrame(cross_validate(classifier, X_train, y_train, scoring=score_method, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>8.642796</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.774651</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.817697</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.772250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>2.046312</td>\n",
       "      <td>0.025767</td>\n",
       "      <td>0.762367</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.388395</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>0.757898</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.160699</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.690253</td>\n",
       "      <td>0.773068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.479016</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fit_time  score_time  test_score  train_score\n",
       "CatBoost             8.642796    0.006026    0.774651     1.000000\n",
       "XGBoost              0.817697    0.007424    0.772250     1.000000\n",
       "random forest        2.046312    0.025767    0.762367     1.000000\n",
       "LightGBM             0.388395    0.012366    0.757898     1.000000\n",
       "logistic regression  0.160699    0.004880    0.690253     0.773068\n",
       "decision tree        0.180556    0.002764    0.479016     1.000000"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results).T\n",
    "results.sort_values(by=[\"test_score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My thoughts:\n",
    "\n",
    "- Keep in mind all of the above is with:\n",
    "  - Default hyperparameters (except `class_weight`)\n",
    "  - A particular scoring metric\n",
    "  - 5-fold CV\n",
    "- All the trees totally overfit\n",
    "  - We may do better by tweaking the hyperparameters\n",
    "- Look at the fit times! And the score times are also interesting.\n",
    "- Note that CatBoost took about 10x longer than XGBoost and the scores only differ by <1%\n",
    "  - We took the mean of the sub-scores, but we might want to look more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What classifier should I use?!\n",
    "\n",
    "- Cop out answer: whichever gets the highest CV score.\n",
    "  - But we shouldn't overuse the validation set.\n",
    "  - This seems more reasonable when you have more data.\n",
    "  - It's time-consuming.\n",
    "- You may also have a reason to choose one over another.\n",
    "- One reason is _interpretability_, which we'll talk a bit more about next week.\n",
    "  - This is an area of growing interest and concern in ML.\n",
    "- Other considerations could be speed (fit and/or predict), maintainability of the code.\n",
    "- Finally, you could use all of them! (That's what the rest of today is about!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break (5 min)\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: averaging (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we looked at a bunch of classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic regression': Pipeline(steps=[('scale', StandardScaler()),\n",
       "                 ('lr', LogisticRegression(max_iter=1000))]),\n",
       " 'decision tree': DecisionTreeClassifier(class_weight='balanced'),\n",
       " 'random forest': RandomForestClassifier(class_weight='balanced'),\n",
       " 'XGBoost': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=500, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       " 'LightGBM': LGBMClassifier(class_weight='balanced'),\n",
       " 'CatBoost': <catboost.core.CatBoostClassifier at 0x7fa732741580>}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we training a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model = VotingClassifier(list(classifiers.items()), voting='soft') # need the list() here for cross_val to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This `VotingClassifier` will take a _vote_ using the predictions of the constituent classifiers.\n",
    "  - Or, more generally, classifier pipelines!\n",
    "- Note the `voting='soft'`\n",
    "  - By default (`voting='hard'`) it uses the output of `predict` and actually votes.\n",
    "  - with `voting='soft'` it averages the output of `predict_proba` and then thresholds / takes the larger.\n",
    "  - The choice depends on whether you trust `predict_proba` from your base classifiers - if so, it's nice to access that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it seems sklearn requires us to actually call `fit` on the `VotingClassifier`, instead of passing in pre-fit models. This is an implementation choice rather than a conceptual limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaging_model.predict(X_test[100:101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hard voting, these are the votes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic regression': 1,\n",
       " 'decision tree': 0,\n",
       " 'random forest': 1,\n",
       " 'XGBoost': 1,\n",
       " 'LightGBM': 1,\n",
       " 'CatBoost': 1}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = {name : classifier.predict(X_test[100:101])[0] for name, classifier in averaging_model.named_estimators_.items()}\n",
    "r1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For soft voting, these are the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.068658</td>\n",
       "      <td>0.931342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.999318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.999211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1\n",
       "logistic regression  0.068658  0.931342\n",
       "decision tree        1.000000  0.000000\n",
       "random forest        0.300000  0.700000\n",
       "XGBoost              0.000010  0.999990\n",
       "LightGBM             0.000682  0.999318\n",
       "CatBoost             0.000789  0.999211"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = {name : classifier.predict_proba(X_test[100:101])[0] for name, classifier in averaging_model.named_estimators_.items()}\n",
    "pd.DataFrame(r2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.228356\n",
       "1    0.771644\n",
       "dtype: float64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(r2).T.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Aside: the probability scores from `DecisionTreeClassifier` are pretty bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       11.506279\n",
       "score_time      0.068168\n",
       "test_score      0.785969\n",
       "train_score     1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vot_res = pd.DataFrame(cross_validate(averaging_model, X_train, y_train, scoring=score_method, return_train_score=True)).mean()\n",
    "vot_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>11.506279</td>\n",
       "      <td>0.068168</td>\n",
       "      <td>0.785969</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>8.642796</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.774651</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.817697</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.772250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>2.046312</td>\n",
       "      <td>0.025767</td>\n",
       "      <td>0.762367</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.388395</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>0.757898</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.160699</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.690253</td>\n",
       "      <td>0.773068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.479016</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fit_time  score_time  test_score  train_score\n",
       "Voting               11.506279    0.068168    0.785969     1.000000\n",
       "CatBoost              8.642796    0.006026    0.774651     1.000000\n",
       "XGBoost               0.817697    0.007424    0.772250     1.000000\n",
       "random forest         2.046312    0.025767    0.762367     1.000000\n",
       "LightGBM              0.388395    0.012366    0.757898     1.000000\n",
       "logistic regression   0.160699    0.004880    0.690253     0.773068\n",
       "decision tree         0.180556    0.002764    0.479016     1.000000"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_avg = pd.concat((results, pd.DataFrame(vot_res, columns=[\"Voting\"]).T))\n",
    "results_with_avg.sort_values(by=[\"test_score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we did a bit better than even our best classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Question: how could the average do better than the best model???\n",
    "  - From the perspective of the best estimator (in this case CatBoost), why are you adding on worse estimators??\n",
    "  \n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how this can work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Example | log reg    | rand for     | cat boost    | Averaged model |\n",
    "|--------|--------|--------|---------|---------------|\n",
    "|  1     | ✅    |   ✅    | ❌     | ✅✅❌=>✅  |\n",
    "|  2     | ✅    |   ❌    | ✅     | ✅❌✅=>✅  |\n",
    "|  3     | ❌    |   ✅    | ✅     | ❌✅✅=>✅  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, as long as the different models make different mistakes, this can work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is amazing, why not always do this?\n",
    "\n",
    "1. `fit`/`predict` time.\n",
    "2. Reduction in interpretability.\n",
    "3. Reduction in code maintainability (e.g. Netflix prize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to ensembling: when can I do this?\n",
    "\n",
    "- You can comebine completely different estimators, or similar estimators.\n",
    "  - (In fact, a random forest itself is an ensemble of decision trees.)\n",
    "- But you can also try different hyperparameter values.\n",
    "  - So... the hyperparameters of the ensemble now go even deeper.\n",
    "  - The inception never ends... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: stacking (20 min)\n",
    "\n",
    "- Another type of ensemble is stacking.\n",
    "- Instead of averaging the outputs of each estimator, instead use their outputs as _inputs to another model_.\n",
    "- By default for classification, it uses logistic regression.\n",
    "  - We don't need a complex model here necessarily, more of a weighted average.\n",
    "  - The features going into the logistic regression are the classifier outputs, _not_ the original features!\n",
    "  - So the number of coefficients = the number of base estimators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code starts to get too slow here; I'm going to remove CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_nocat = classifiers.copy()\n",
    "del classifiers_nocat[\"CatBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingClassifier(list(classifiers_nocat.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on in here? \n",
    "\n",
    "- It is doing cross-validation by itself by default (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html))\n",
    "  - It is fitting the base estimators on the training fold\n",
    "  - And the predicting on the validation fold\n",
    "  - And then fitting the meta-estimator on that output (on the validation fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.predict(X_test[100:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08733487, 0.91266513]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.predict_proba(X_test[100:101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This is the `predict_proba` from logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       16.922682\n",
       "score_time      0.057425\n",
       "test_score      0.781834\n",
       "train_score     1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(stacking_model, X_train, y_train, scoring=score_method, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The situation here is a bit mind-boggling.\n",
    "- AFAIK on each fold of cross-validation it is doing cross-validation.\n",
    "- And then in there you might have pipelines and...\n",
    "- This is really loops within loops within loops within loops..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the input features (X) to the meta-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.068658</td>\n",
       "      <td>0.931342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.999318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1\n",
       "logistic regression  0.068658  0.931342\n",
       "decision tree        1.000000  0.000000\n",
       "random forest        0.310000  0.690000\n",
       "XGBoost              0.000010  0.999990\n",
       "LightGBM             0.000682  0.999318"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3 = {name : classifier.predict_proba(X_test[100:101])[0] for name, classifier in stacking_model.named_estimators_.items()}\n",
    "r3 = pd.DataFrame(r3).T\n",
    "r3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Because this needs to work for multi-class now I'm not quite sure if both probabilities are going in or just one - I think just one - this is a bit simpler for regression!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the meta-model is logistic regression (which it is by default), you are taking a weighted average of these outputs and learning the weights from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.65468467, 1.11690141, 2.30038883, 3.02946163, 2.57597216]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>2.654685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>1.116901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>2.300389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>3.029462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>2.575972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coefficient\n",
       "logistic regression     2.654685\n",
       "decision tree           1.116901\n",
       "random forest           2.300389\n",
       "XGBoost                 3.029462\n",
       "LightGBM                2.575972"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=stacking_model.final_estimator_.coef_[0], index=classifiers_nocat.keys(), columns=[\"Coefficient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It seems that the XGBoost is being trusted the most / counting for most.\n",
    "- We can also try a different final estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model_tree = StackingClassifier(list(classifiers_nocat.items()), \n",
    "                                        final_estimator=DecisionTreeClassifier(max_depth=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       19.168481\n",
       "score_time      0.062120\n",
       "test_score      0.652996\n",
       "train_score     0.923158\n",
       "dtype: float64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(stacking_model_tree, X_train, y_train, scoring=score_method, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model_tree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not very good. But we can look at the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"637pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 636.50 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 632.5,-256 632.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"424.5,-252 282.5,-252 282.5,-216 424.5,-216 424.5,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"353.5\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">random forest &lt;= 0.22</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"355,-180 182,-180 182,-144 355,-144 355,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"268.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logistic regression &lt;= 0.112</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M332.0509,-215.8314C321.6822,-207.0485 309.0771,-196.3712 297.8354,-186.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"299.8349,-183.9556 289.9422,-180.1628 295.3105,-189.297 299.8349,-183.9556\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.0052\" y=\"-201.3776\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"506,-180 373,-180 373,-144 506,-144 506,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"439.5\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LightGBM &lt;= 0.027</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M375.2014,-215.8314C385.6921,-207.0485 398.4455,-196.3712 409.8194,-186.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"412.3847,-189.2659 417.8055,-180.1628 407.8911,-183.8986 412.3847,-189.2659\"/>\n",
       "<text text-anchor=\"middle\" x=\"415.599\" y=\"-201.3653\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"173,-108 0,-108 0,-72 173,-72 173,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.5\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logistic regression &lt;= 0.001</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M222.5737,-143.8314C197.9077,-134.0734 167.3309,-121.977 141.414,-111.7242\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"142.6824,-108.4621 132.096,-108.038 140.1073,-114.9713 142.6824,-108.4621\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"364,-108 191,-108 191,-72 364,-72 364,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logistic regression &lt;= 0.119</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M270.7711,-143.8314C271.7336,-136.131 272.8782,-126.9743 273.9479,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.4309,-118.7702 275.1983,-108.4133 270.4849,-117.9019 277.4309,-118.7702\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"77.5,-36 11.5,-36 11.5,0 77.5,0 77.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"44.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M75.9016,-71.8314C71.2123,-63.7925 65.5972,-54.1666 60.4202,-45.2918\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"63.3031,-43.2875 55.2411,-36.4133 57.2566,-46.8146 63.3031,-43.2875\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"161.5,-36 95.5,-36 95.5,0 161.5,0 161.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"128.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M97.0984,-71.8314C101.7877,-63.7925 107.4028,-54.1666 112.5798,-45.2918\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"115.7434,-46.8146 117.7589,-36.4133 109.6969,-43.2875 115.7434,-46.8146\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"278.5,-36 212.5,-36 212.5,0 278.5,0 278.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"245.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M269.425,-71.8314C265.8898,-63.8771 261.664,-54.369 257.7544,-45.5723\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.9435,-44.1299 253.6837,-36.4133 254.5468,-46.9729 260.9435,-44.1299\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"362.5,-36 296.5,-36 296.5,0 362.5,0 362.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M290.6218,-71.8314C296.5499,-63.6232 303.6729,-53.7606 310.1933,-44.7323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.184,-46.5693 316.2015,-36.4133 307.5092,-42.4708 313.184,-46.5693\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"464.5,-108 398.5,-108 398.5,-72 464.5,-72 464.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"431.5\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M437.4813,-143.8314C436.6257,-136.131 435.6083,-126.9743 434.6574,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"438.1289,-117.9656 433.5459,-108.4133 431.1717,-118.7386 438.1289,-117.9656\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"624.5,-108 482.5,-108 482.5,-72 624.5,-72 624.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"553.5\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">random forest &lt;= 0.97</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>8&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M468.267,-143.8314C482.7133,-134.7074 500.3965,-123.539 515.904,-113.7449\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"518.1563,-116.462 524.7422,-108.1628 514.4183,-110.5436 518.1563,-116.462\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"544.5,-36 478.5,-36 478.5,0 544.5,0 544.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"511.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M542.9016,-71.8314C538.2123,-63.7925 532.5972,-54.1666 527.4202,-45.2918\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"530.3031,-43.2875 522.2411,-36.4133 524.2566,-46.8146 530.3031,-43.2875\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"628.5,-36 562.5,-36 562.5,0 628.5,0 628.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"595.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M564.0984,-71.8314C568.7877,-63.7925 574.4028,-54.1666 579.5798,-45.2918\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"582.7434,-46.8146 584.7589,-36.4133 576.6969,-43.2875 582.7434,-46.8146\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa72f3b3fa0>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_tree(list(classifiers_nocat.keys()), stacking_model_tree.final_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is so cool!! (Well,  think so)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An effective strategy\n",
    "\n",
    "- Randomly generate a bunch of models with different hyperparameter configurations, and then stack all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "- There's a big world of classifiers out there.\n",
    "  - Tree-based classifiers are particularly popular and effective on a wide range of problems. \n",
    "  - These can be much more complex than LogisticRegression, which only learns one coefficient per feature.\n",
    "- We sometimes need to leave the world of scikit-learn (and more of that later in the course!).\n",
    "- Ensembles are usually pretty effective.\n",
    "  - But they trade off code complexity and code speed for prediction accuracy.\n",
    "  - Don't forget that hyperparameter optimization multiplies the slowness of the code!\n",
    "- Stacking is a bit slower than voting, but generally more accuracy.\n",
    "  - As a bonus, you get to see the coefficients for each base classifier.\n",
    "- Remember, everything we've done is subject to earlier warnings:\n",
    "  - Check for small datasets\n",
    "  - Check the CV folds\n",
    "  - Check the test set\n",
    "  - Think carefully about which scoring metric is suitable for your problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## True/False questions (Piazza)\n",
    "\n",
    "1. I can decide to average different models even _after_ I (or someone else) have already trained them.\n",
    "2. Let estimators A, B, and C have scores of 90%, 70%, and 70%, respectively. Then, the maximum score of an ensemble is 90%. \n",
    "3. Let estimators A, B, and C have scores of 70%, 70%, and 70%, respectively. Then, the minimum score of an ensemble is 70%.\n",
    "4. Ensembling often increase your score but they also increase the time spent fitting and predicting.\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
