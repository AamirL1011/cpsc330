{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 Lecture 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "\n",
    "- Announcements + survey (5 min)\n",
    "- Model deployment (30 min)\n",
    "- Instructor/TA evaluations + Break (15 min)\n",
    "- Combining multiple tables (10 min)\n",
    "- Conclusion (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder to self: **turn on recording!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "import sklearn.datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These next 3 cells could just be replaced with `import load_process_data`.\n",
    "- But this way I can make changes to that file and not need to restart my kernel each time.\n",
    "- So it's convenient for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_classifier import plot_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "\n",
    "- this year we already introduced these in lecture 9\n",
    "- but we still shoud talk about how CatBoost handles categoricals? And some other details below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores_factory(X_train, y_train, X_test, y_test):\n",
    "    def show_scores(model, **fit_kwargs):\n",
    "        model.fit(X_train, y_train, **fit_kwargs);\n",
    "        return model.score(X_test, y_test)\n",
    "    return show_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements\n",
    "\n",
    "Same as last class:\n",
    "\n",
    "- hw7 has been posted, due Sunday evening.\n",
    "  - I tried to make it shorter than previous assignments.\n",
    "- Tutorials are still happening as scheduled, on Collaborate Ultra.\n",
    "- Change to course grading scheme per Dean's directive; see [here](https://piazza.com/class/k1gx4b3djbv3ph?cid=319)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's class:\n",
    "\n",
    "- A bunch of random things I wanted to cover at some point.\n",
    "- Next week: communication and ethics (hopefully)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "end of course survey (about 340)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break (15 min)\n",
    "\n",
    "Please take the opportunity to fill out the course evaluations.\n",
    "\n",
    "https://canvas.ubc.ca/courses/53561/external_tools/4732"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted trees (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently a lot of the winning models have been one of the following:\n",
    "\n",
    "|  Name   |  GitHub |  web/docs | Year | GitHub stars |\n",
    "|---------|---------|---------|---------|--------------|\n",
    "|  XGBoost | [link](https://github.com/dmlc/xgboost) | [link](https://xgboost.ai/) | 2016 | 19k\n",
    "| LightGBM |  [link](https://github.com/microsoft/LightGBM) | [link](https://lightgbm.readthedocs.io/en/latest/) |  2017 | 11k |\n",
    "| CatBoost | [link](https://github.com/catboost/catboost) | [link](https://catboost.ai/) | 2017 | 5k |\n",
    "\n",
    "When I checked, all repos updated in the last 24 hrs (i.e., active development)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All of these implement [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting), which is beyond the scope of the course.\n",
    "  - And not covered in 340, but it probably should be!\n",
    "- These 3 packages are fairly similar. Today I'll focus on CatBoost.\n",
    "- I believe CatBoost and LightGBM seems to be performing better than XGBoost these days, but they are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I avoided these earlier in the course because I thought they'd be hard to install.\n",
    "- It seems a lot of issues were solved since I tried XGBoost 1-2 years ago - it was easy!\n",
    "- I think next time I might put these a lot earlier and use CatBoost instead of sklearn random forests everywhere, because I think it's a better choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variables\n",
    "\n",
    "- Of these 3, CatBoost is special because of how it handles categorical variables - hence \"Cat\".\n",
    "- Thinking back to decision trees, we talked about splits like `Humidity > 1.2` or `Longitude > 90`. \n",
    "- Because we OHE categorical variables, it will give splits like `Location_Sydney > 0.5`, where that number 0.5 could be anywhere between 0 and 1. \n",
    "- (First off, there is no reason sklearn's decision trees or random forests need to require OHE; they could have easily learned rules like `Location == 'Sydney'`, which is equivalent to `Location_Sydney > 0.5` after OHE. I believe they didn't do this to be consistent with other sklearn estimators. However, I wonder if this makes performance worse, in particular for random forests.)\n",
    "- However, is OHE the best encoding? Do we want 100 columns if there are 100 categories? What about `drop='first'` and `handle_error='ignore'`. It seems like a lot of hassle.\n",
    "- CatBoost uses a more sophisticated encoding from categorical to numeric; see [here](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html#algorithm-main-stages_cat-to-numberic).\n",
    "  - From the documentation: \"Before each split is selected in the tree (see Choosing the tree structure), categorical features are transformed to numerical. This is done using various statistics on combinations of categorical features and combinations of categorical and numerical features.\"\n",
    "  - This makes me think the conversion is done separately _at each split_.\n",
    "  - So we can't just do this transformation in advance, it is entangled deeply with the algorithm. \n",
    "  - And also this makes sense, since the popularity of each value will change as your split the data.\n",
    "  - Importantly, if there are 100 possible categories, you may not end up with 100 columns.\n",
    "  - (From my reading of the documentation it looks like you end up with some smaller number of columns, depending on the type of _targets_: one per class for classification, and for regression this is controlled by a hyperparameter $k$.)\n",
    "  - (Interestingly, the number of columns does not seem to depend on the number of possible categories of the categorical variable!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_housing, X_valid_housing, X_test_housing, y_train_housing, y_valid_housing, y_test_housing = load_process_data.load_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_housing_log = np.log(y_train_housing)\n",
    "y_valid_housing_log = np.log(y_valid_housing)\n",
    "y_test_housing_log  = np.log(y_test_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_housing = show_scores_factory(X_train_housing, y_train_housing_log, X_valid_housing, y_valid_housing_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_housing(Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_housing(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_housing(xgb.XGBRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_housing(lgb.LGBMRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_housing(CatBoostRegressor(), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we try with proper handling of categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_housing_cat, X_valid_housing_cat, X_test_housing_cat, y_train_housing, y_valid_housing, y_test_housing, categorical_features = load_process_data.load_housing(ohe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_housing_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_housing_cat[categorical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\", \".join(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostRegressor(cat_features=categorical_features)\n",
    "cat.fit(X_train_housing_cat, y_train_housing_log, verbose=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.score(X_valid_housing_cat, y_valid_housing_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the code ran slower and it didn't seem to help, but I suspect it will in some cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The syntax for getting feature importances is a bit clunky.\n",
    "- You first need to create a `catboost.Pool` object storing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pool = Pool(X_train_housing_cat, y_train_housing_log, cat_features=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can get feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = cat.get_feature_importance(train_data_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can display them as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(data=importances, index=X_train_housing_cat.columns, columns=[\"Importance\"])\n",
    "importances.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\", \".join(categorical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also get SHAP values, both through the SHAP package or built-in to CatBoost.\n",
    "- With proper handling of categorical variables, we can see an importance for the entire categorical variable, not just one possible value of it, which is kind of nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very rough rule of thumb, when working on a problem with **tabular data**, try the following, in order: \n",
    "\n",
    "1. `DummyRegressor` or `DummyClassifer`\n",
    "2. `HuberRegressor` or `LogisticRegression`\n",
    "3. `CatBoostRegressor` or `CatBoostClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now do a \"bake-off\" between different models and different datasets in the course, following the outlier scavenger hunt from L19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Census data (lecture 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adult, y_train_adult, X_test_adult, y_test_adult, _ = load_process_data.load_adult()\n",
    "X_train_adult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_adult = show_scores_factory(X_train_adult, y_train_adult, X_test_adult, y_test_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_adult(DummyClassifier(strategy=\"prior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_adult(LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_adult(xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_adult(lgb.LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_adult(CatBoostClassifier(), verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adult_cat, y_train_adult, X_test_adult_cat, y_test_adult, cat_features_adult = load_process_data.load_adult(ohe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adult_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(cat_features=cat_features_adult)\n",
    "cat.fit(X_train_adult_cat, y_train_adult, verbose=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.score(X_test_adult_cat, y_test_adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "compare on AUC as well, accuracy might not be as meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie review data (lecture 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imdb, y_train_imdb, X_test_imdb, y_test_imdb = load_process_data.load_movie()\n",
    "X_train_imdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_movie = show_scores_factory(X_train_imdb, y_train_imdb, X_test_imdb, y_test_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_movie(DummyClassifier(strategy=\"prior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_movie(LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_movie(xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM seems to kill my kernel in this case... too many features?? Or maybe it can't handle sparse matrices as input? That seems surprising though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_scores_movie(lgb.LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_movie(CatBoostClassifier(), verbose=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no categorical features here (they are all word counts), so no need to do another experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rain in Australia data (lecture 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rain, y_train_rain, X_test_rain, y_test_rain, _ = load_process_data.load_rain()\n",
    "X_train_rain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_rain = show_scores_factory(X_train_rain, y_train_rain, X_test_rain, y_test_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_rain(DummyClassifier(strategy=\"prior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_rain(LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_rain(xgb.XGBClassifier(verbosity=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_rain(lgb.LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_rain(CatBoostClassifier(), verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rain_cat, _, X_test_rain_cat, _, cat_features_rain = load_process_data.load_rain(ohe=False)\n",
    "X_train_rain_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rain_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(iterations=500, cat_features=cat_features_rain)\n",
    "cat.fit(X_train_rain_cat, y_train_rain, verbose=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.score(X_test_rain_cat, y_test_rain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- Overall CatBoost looks like a good bet. \n",
    "- We didn't do any hyperparameter tuning, this might change the results. Maybe they just have better defaults.\n",
    "  - In fact, we did not discuss hyperparameters at all for these fancy models.\n",
    "  - There are a ton of them!\n",
    "  - For CatBoost, a main hyperparameter controlling the fundamental tradeoff is `iterations`. \n",
    "    - This is similar to `n_estimators` in the sklearn random forests: larger = more complex models.\n",
    "  - Another main hyperparameter is `learning_rate` but its interpretation is a bit beyond our scope.\n",
    "  - These models should all be compatible with `RandomizedSearchCV`, etc.\n",
    "  - But CatBoost, at least, does not work out of the box for feature selection with `RFE`/`RFECV`\n",
    "- But I think it's pretty good. A bit slow though.\n",
    "  - Now that speed is an issue, we should note that increasing complexity via `iterations` also increases runtime.\n",
    "  - This is not always true, e.g. `gamma` in SVM and (for the most part) `C` in `LogisticRegression`.\n",
    "  - But in fact often we did get increased runtime with more complexity, e.g. more features from `CountVectorizer`. \n",
    "- I'm surprising that feeding in the raw categorical features doesn't seem to help in many cases. \n",
    "  - Isn't that the point of CatBoost?!\n",
    "  - It does seem to help with the Rain data.\n",
    "  - I will need to look into this more at some point.\n",
    "    - Maybe the code needs to be run for longer in these cases?\n",
    "    - Hyperparameter tuning should be done in each case, at least a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break (5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining multiple tables (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a look at the [Formula 1 race data set](https://www.kaggle.com/cjgdev/formula-1-race-data-19502017) from Kaggle. \n",
    "- The dataset contains **multiple CSV files**.\n",
    "- Let's read in one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_results_df = pd.read_csv(\"data/formula-1-race-data-19502017/results.csv\", index_col=0)\n",
    "racing_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's say we want to predict the `milliseconds` column, namely the total length of time it takes a driver to finish a race. \n",
    "- In that case, we should not have access to most of these other columns. \n",
    "- But we would have the `raceId` and `driverId`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_results_df_subset = racing_results_df.dropna(subset=[\"milliseconds\"])[['raceId', 'driverId', 'milliseconds']]\n",
    "racing_results_df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_train, racing_test = train_test_split(racing_results_df_subset, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try some baselines based on the ID values themselves, although:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cross_validate(DummyRegressor(), racing_train[[\"raceId\", \"driverId\"]], \n",
    "                            racing_train[\"milliseconds\"], return_train_score=True, cv=20)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = make_pipeline(OneHotEncoder(handle_unknown='ignore'), Ridge())\n",
    "pd.DataFrame(cross_validate(lr, racing_train[[\"raceId\", \"driverId\"]], \n",
    "                            racing_train[\"milliseconds\"], return_train_score=True, cv=20)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is actually pretty good *facepalm*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But we'd like some more/better features to predict the race time. \n",
    "- Enter the other tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_drivers_df = pd.read_csv(\"data/formula-1-race-data-19502017/drivers.csv\", \n",
    "                                encoding='latin-1', index_col=0,\n",
    "                               parse_dates=['dob'])\n",
    "racing_drivers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can we use the driver's nationality and age as features?\n",
    "- `pd.merge` can take care of this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(racing_results_df_subset, racing_drivers_df, on=\"driverId\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `on` keyword told it which column to use to match up the rows of the two dataframes.\n",
    "- Note that the first 5 rows have the same `driverId`, so they pulled the same data from `racing_drivers_df`.\n",
    "- Now we could keep only the columns we plan to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_subset = merged_df[['raceId', 'driverId', 'milliseconds', 'dob', 'nationality']]\n",
    "merged_df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can process the `dob` column to get age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = (pd.Timestamp.now() - merged_df_subset[\"dob\"]).apply(lambda x: x.total_seconds()/3600/24/365)\n",
    "merged_df_age = merged_df_subset.assign(age=ages)\n",
    "merged_df_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So far we got information for each driver.\n",
    "- Likewise, we can get information about the races, and use those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_races_df = pd.read_csv(\"data/formula-1-race-data-19502017/races.csv\", encoding='latin-1', index_col=0)\n",
    "racing_races_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For those who have taken CPSC 304 or some have other database training, you'll recognize this type of multi-table situation, with foreign keys connecting the tables.\n",
    "- `pd.merge` supports several types of joins, see the documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_full = pd.merge(merged_df_age, racing_races_df, on=\"raceId\")\n",
    "merged_df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we just take the circuit ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_final = merged_df_full.drop(columns=[\"dob\", \"name\", \"date\", \"time\", \"url\"])\n",
    "merged_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"raceId\", \"driverId\", \"nationality\", \"round\", \"circuitId\"]\n",
    "numeric_features = [\"age\", \"year\"]\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    (StandardScaler(), numeric_features)\n",
    ")\n",
    "lr = make_pipeline(preprocessing, Ridge())\n",
    "pd.DataFrame(cross_validate(lr, merged_df_final.drop(columns=[\"milliseconds\"]), \n",
    "                            merged_df_final[\"milliseconds\"], return_train_score=True, cv=20)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ok, something went terribly wrong here that I will need to investigate.\n",
    "- This turned out to be a disastrous example.\n",
    "- But you can get the idea that combining multiple tables might be useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing.fit(merged_df_final)\n",
    "# ohe_columns = list(preprocessing.named_transformers_['onehotencoder'].get_feature_names(categorical_features))\n",
    "# new_columns = ohe_columns + numeric_features\n",
    "# lr_coefs = pd.DataFrame(data=lr[1].coef_, index=new_columns, columns=[\"Coefficient\"])\n",
    "# lr_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True/False questions (15 min)\n",
    "\n",
    "1. `CatBoost` is effective because, when increasing `iterations`, you lower the training error and the approximation error. \n",
    "2. `CatBoost` is likely to be popular in 10 years.\n",
    "3. The primary motivation for using `SGDClassifier` or `SGDRegressor` is speed.\n",
    "4. In multi-class logistic regression, if the coefficient for feature 10, class 2 is positive, that means increasing the value of feature 10 _decreases_ the predicted probability of class 1 (a different class).\n",
    "5. If we are dealing with data from multiple sources, our strategy is to first combine them as a preprocessing step, and then build a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course review (15 min)\n",
    "\n",
    "#### Learning objectives\n",
    "\n",
    "Here are the course learning outcomes I came up with when proposing this new course:\n",
    "\n",
    "1. Identify problems that may be addressed with machine learning.\n",
    "2. Select the appropriate machine learning tool for a problem.\n",
    "3. Transform data of various types into usable features.\n",
    "4. Apply standard tools implementing supervised and unsupervised learning techniques.\n",
    "5. Describe core differences between training, validation, and testing regimes.\n",
    "6. Effectively communicate the results of a machine learning pipeline.\n",
    "7. Be realistic about the limitations of individual approaches and machine learning as a whole. \n",
    "8. Create reproducible workflows and pipelines.\n",
    "\n",
    "- How did we do? \n",
    "- Hopefully OK, except we skipped the last point (that will likely be its own new course).\n",
    "- I would also add:\n",
    "\n",
    "9. Identify and avoid scenarios in which training and testing data are accidentally mixed (the \"Golden Rule\").\n",
    "10. Employ good habits for applying ML, such as starting an analysis with a baseline estimator.\n",
    "\n",
    "because I think they are important enough to make it to the course-level list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What did we cover?\n",
    "\n",
    "I see the course roughly like this (not in order):\n",
    "\n",
    "Part 1: Supervised learning on tabular data\n",
    "\n",
    "- Overfitting, train/validation/test/deployment, cross-validation\n",
    "- Feature preprocessing, pipelines, imputation, OHE, etc\n",
    "- The Golden Rule, various ways to accidentally violate it\n",
    "- Classification metrics: confusion matrix, precision/recall, ROC, AUC\n",
    "- Regression metrics: MSE, MAPE\n",
    "- Regression: transforming the targets\n",
    "- Feature importances, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Other data types (non-tabular)\n",
    "\n",
    "- Time series\n",
    "- Right-censored data / survival analysis\n",
    "- Computer vision with deep learning\n",
    "- Language data, text preprocessing\n",
    "- Ratings data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Other stuff\n",
    "\n",
    "- Some Python (numpy, pandas, scipy sparse matrices)\n",
    "- Hyperparameter optimization\n",
    "- Ensembles\n",
    "- Outlier detection\n",
    "- Clustering\n",
    "- A bunch of models: \n",
    "  - Dummy*\n",
    "  - linear models (ridge, lasso, huber, logistic regression, SGD*)\n",
    "  - tree-based models (random forest, gradient boosted trees)\n",
    "  - KNN classifier/regressor\n",
    "  - pre-trained deep learning models\n",
    "- Communicating your results (including visualizations)\n",
    "- ML skepticism\n",
    "- Ethics for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would I do differently?\n",
    "\n",
    "Lots of things, of course! Here are some important ones:\n",
    "\n",
    "- Introduce `Pipeline` earlier.\n",
    "- Throughout the course, default to cross-validation instead of train/valid split.\n",
    "- Find a dataset with multi-class classification for a section of the course.\n",
    "- Spend more time on quantifying the uncertainty in one's results (scores, predictions, feature importances, etc).\n",
    "- Add a lecture on deploying a trained model.\n",
    "- Skip some of the content on text preprocessing.\n",
    "- Skip some of the content on SVMs.\n",
    "- Skip `Lasso`?\n",
    "\n",
    "I'm sure you have other suggestions - feel free to drop me an email, submit my contact form anonymously at mikegelbart.com, or drop them in the course evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 330 vs. 340\n",
    "\n",
    "- Just talked about it - see recording.\n",
    "\n",
    "# TODO - add this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was not covered\n",
    "\n",
    "- Deployment\n",
    "- Big data, distributed computing\n",
    "- How ML methods work (CPSC 340)\n",
    "- Probabilistic methods\n",
    "- A lot of unsupervised learning, semi-supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsolicited advice: working with others (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I sometimes end my courses with \"unsolicited life advice\".\n",
    "- I won't repeat myself here because some of you took CPSC 340 with me. But if you're interested [it's on YouTube](https://www.youtube.com/watch?v=_7zYxpzrKmQ&list=PLWmXHcz_53Q02ZLeAxigki1JZFfCO6M-b&index=34&t=0s).\n",
    "- Instead of general life advice I'll try a different topic this time: unsolicited advice on _working with others_.\n",
    "- These are just my opinions. They not be complete, or correct. Follow my advice at your own risk!\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't lead with blame - investigate first\n",
    "\n",
    "Leading with blame:\n",
    "\n",
    "> Hey Malcolm, you were supposed to submit this form by the deadline - why didn't you?\n",
    "\n",
    "Instead, try this:\n",
    "\n",
    "> Hey Malcolm, from my end it looks like the form hasn't been submitted - can you shed some light on the situation?\n",
    "\n",
    "- Blaming others is very embarrassing and damaging if the blame is not deserved.\n",
    "- And also not great if the blame _is_ deserved.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fundamental attribution error\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Fundamental_attribution_error\n",
    "- If you miss a deadline: “I was too busy moving apartments.”\n",
    "- If your teammate misses a deadline: “They are incompetent.”\n",
    "- This is a known psychological phenomenon, so try to correct for this. Are you sure you know why they missed the deadline?\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't procrastinate on disappointing others\n",
    "\n",
    "- This can be highly damaging, and is a serious form of procrastination.\n",
    "- If you need to break a commitment, communicate this right away. \n",
    " - Can't get your work done on time.\n",
    " - Need to pull out of a project.\n",
    " - Need to move your organization to another city.\n",
    "- Consider how much better this is for the person being disappointed.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your opinion is not special\n",
    "\n",
    "- If you disagree with someone, why do you think you're more likely to be right than the other person?\n",
    "  - After all, there's a symmetry to the situation.\n",
    "- I think most people are in denial about this.\n",
    "  - That is, if you take an issue (e.g. \"will lowering taxes improve the economy?\", or religious beliefs), the credence of opposing sides are likely both above 50%. \n",
    "- A good question to ask yourself: is there data? E.g. if you are always on time and your co-worker is always late, then OK to trust your opinion on scheduling.\n",
    "- My approach:\n",
    "  - For critical decisions: try to \"average\" different opinions, including my own, based on trustworthiness.\n",
    "  - For most decisions: do it my way because life is more fun that way.\n",
    "  \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That's all, folks! Thank you for your active participation and supportive attitude."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
